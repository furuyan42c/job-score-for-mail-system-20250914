# 技術リサーチ: バイト求人マッチングシステム

**作成日**: 2025-09-17
**関連仕様**: `/specs/002-think-hard-ultrathink/spec.md`
**ステータス**: 確定

## エグゼクティブサマリー

本システムは、10万件の求人データから1万人のユーザーそれぞれに最適な40件を選定する大規模マッチングシステムです。既存実装（specs/001-job-matching-system）の分析とベストプラクティスリサーチに基づき、Python/FastAPI + Next.js + Supabaseのスタックを採用します。

## 技術選定

### バックエンド技術スタック

**決定**: Python 3.11 + FastAPI
- **根拠**:
  - 高速な非同期処理によるバッチ処理の並列化
  - pandas/NumPyとの優れた統合性
  - 既存実装（answers.md）との整合性
- **検討された代替案**:
  - Django: より重量で、リアルタイム処理には不向き
  - Node.js: データ処理ライブラリが劣る
  - Go: チーム習熟度の問題

### フロントエンド技術スタック

**決定**: Next.js 14 (App Router) + TypeScript
- **根拠**:
  - SSR/SSGによる高速な初期表示
  - TypeScriptによる型安全性
  - React 18の並行レンダリング
- **検討された代替案**:
  - Vue.js: エコシステムが小さい
  - vanilla React: SSRの実装が複雑

### データベース

**決定**: Supabase (PostgreSQL 15)
- **根拠**:
  - リアルタイムクエリ実行のための高速性
  - 既存データ構造（ER図）との整合性
  - 充実したSQL機能とインデックス
- **検討された代替案**:
  - MySQL: ウィンドウ関数のサポートが弱い
  - MongoDB: SQL実行画面との不整合

## アルゴリズム詳細

### 3段階スコアリング

#### 1. 基礎スコア（0-100）
```python
構成要素:
- 時給スコア (40%): エリア平均との比較
- fee報酬スコア (30%): 500円〜5000円を正規化
- 企業人気度 (30%): 360日の応募率
```

#### 2. SEOスコア（0-100）
```python
計算方法:
- semrush_keywordsテーブルとのマッチング
- search_volume × keyword_difficultyで重み付け
- 複数マッチ時は累積加算（上限100）
```

#### 3. パーソナライズスコア（0-100）
```python
ALS(Alternating Least Squares)パラメータ:
- factors: 50 (潜在因子数)
- regularization: 0.01
- iterations: 15
- alpha: 40 (信頼度)
```

### 6セクション選定ロジック

#### セクション間の重複制御
```python
優先順位:
1. editorial_picks (5件) - fee×応募数
2. top5 (5件) - パーソナライズスコア
3. regional (10件) - 都道府県内
4. nearby (8件) - 市区町村周辺
5. high_income (7件) - 高時給/日払い
6. new (5件) - 7日以内投稿

※上位セクションで選定済みの求人は下位セクションから除外
```

## パフォーマンス最適化戦略

### 並列処理アーキテクチャ
```yaml
Phase 1 (データインポート): 5分
  - CSVの並列読み込み（10スレッド）
  - バルクインサート（1000件/バッチ）

Phase 2 (スコアリング): 10分
  - ユーザーを100グループに分割
  - 各グループを並列処理（10プロセス）
  - NumPyベクトル化演算

Phase 3 (マッチング): 10分
  - 地域別に分割処理
  - メモリ内キャッシュ活用

Phase 4 (メール生成): 5分
  - GPT-5 nano API並列呼び出し（50並列）
  - フォールバック: テンプレートベース生成
```

### データベース最適化
```sql
主要インデックス:
- jobs(endcl_cd, status, created_at)
- user_actions(user_id, endcl_cd, created_at)
- scores(user_id, job_id, total_score)
- jobs_by_location(pref_cd, city_cd, total_score)
```

## モニタリングシステム設計

### リアルタイムSQL実行画面
```typescript
機能:
- クエリバリデーション（読み取り専用）
- 実行計画の可視化
- 結果のページネーション（1000件/ページ）
- クエリ履歴管理
- パフォーマンスメトリクス表示
```

### エラーハンドリング
```python
レベル:
1. 警告: 処理継続、ログ出力
2. エラー: 該当処理スキップ、代替処理
3. クリティカル: バッチ停止、通知送信
```

## セキュリティ考慮事項

### SQLインジェクション対策
- パラメータ化クエリの使用
- 読み取り専用ロールでの実行
- ホワイトリスト方式のクエリ検証

### データ保護
- メールアドレスのハッシュ化保存
- 応募履歴の暗号化
- アクセスログの監査証跡

## 依存ライブラリ詳細

### Python依存関係
```toml
[dependencies]
fastapi = "^0.104.0"
pandas = "^2.1.0"
numpy = "^1.24.0"
scikit-learn = "^1.3.0"
implicit = "^0.7.0"
supabase = "^2.0.0"
apscheduler = "^3.10.0"
openai = "^1.0.0"
pydantic = "^2.0.0"
```

### JavaScript依存関係
```json
{
  "dependencies": {
    "next": "^14.0.0",
    "react": "^18.2.0",
    "typescript": "^5.0.0",
    "@supabase/supabase-js": "^2.38.0",
    "zustand": "^4.4.0",
    "swr": "^2.2.0",
    "tailwindcss": "^3.3.0"
  }
}
```

## 実装上の課題と解決策

### 課題1: 30分以内の処理完了
**解決策**:
- 並列処理の最大活用（100並列まで）
- インメモリキャッシュ（Redis検討）
- インクリメンタル処理（差分のみ更新）

### 課題2: GPT-5 nano APIのレート制限
**解決策**:
- バッチAPIの活用
- フォールバック用テンプレート準備
- リトライロジック実装

### 課題3: 大量データのメモリ管理
**解決策**:
- チャンク処理（1000件単位）
- ジェネレータパターン活用
- 不要データの即座解放

## 既存実装との統合

### 参照すべき既存ファイル
1. `specs/001-job-matching-system/answers.md` - 実装済みコード
2. `specs/001-job-matching-system/comprehensive_integrated_specification_final_v5.0.md` - 詳細仕様
3. `specs/001-job-matching-system/20250904_er_complete_v2.0.mmd` - データベース設計

### 再利用可能なコンポーネント
- スコアリングアルゴリズム（answers.md）
- データベーススキーマ（ER図）
- バッチ処理フレームワーク

## 推奨開発アプローチ

### フェーズ分割
1. **データ基盤** (並列可能)
   - データインポート機能
   - データベーススキーマ実装

2. **バックエンド** (並列可能)
   - スコアリングAPI
   - マッチングAPI
   - バッチ処理

3. **フロントエンド** (並列可能)
   - SQL実行画面
   - ダッシュボード
   - エラーログビューア

### テスト戦略
```yaml
契約テスト:
  - APIエンドポイントのスキーマ検証
  - 30件

統合テスト:
  - データフロー全体の検証
  - 20件

E2Eテスト:
  - ユーザーシナリオの実行
  - 10件

単体テスト:
  - 各関数の動作検証
  - 100件以上
```

## まとめ

本リサーチにより、すべての技術的不明点が解決され、実装準備が整いました。既存実装を最大限活用しつつ、パフォーマンス要件（30分以内）を満たす並列処理アーキテクチャを採用します。

**次のステップ**: フェーズ1（設計＆契約）でdata-model.md、contracts/、quickstart.mdを生成