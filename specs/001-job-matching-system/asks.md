# 🤔 実装前の確認事項: バイト求人マッチングシステム

**作成日**: 2025-09-15  
**目的**: tasks.mdを実行する前に解決すべき曖昧な部分の明確化  
**優先度**: 🔴高 (実装ブロッカー) | 🟡中 (実装に影響) | 🟢低 (最適化関連)

## 📊 分析結果サマリー

tasks.mdの65タスクを分析した結果:
- ✅ **カバレッジ**: 全10個の機能要件(FR-001〜FR-010)はカバー済み
- ⚠️ **曖昧な部分**: 12カテゴリ、約35項目の詳細が未定義（メール文面セクション追加）
- 🎯 **実装可能性**: 基本構造は明確だが、アルゴリズムの詳細が必要

---

## 🔴 優先度: 高（実装ブロッカー）

### 1. スコアリングアルゴリズムの詳細

#### 1.1 基礎スコア計算式
**現状**: "時給、アクセス、福利厚生、人気度の4要素"とあるが、具体的な計算式が不明

**質問**:
```python
# 案A: 加重平均
basic_score = (
    hourly_wage_score * 0.4 +
    access_score * 0.2 +
    benefits_score * 0.2 +
    popularity_score * 0.2
) * 100

# 案B: 正規化後の合計
basic_score = normalize(hourly_wage) + normalize(access) + ...

# どちらが適切ですか？各要素の重み付けは？
```

#### 1.2 SEOスコアのマッチングロジック
**現状**: semrush_keywordsテーブルとのマッチングとあるが、マッチング方法が不明

**質問**:
- 完全一致のみ？部分一致も含む？
- 複数キーワードマッチ時の加算方法は？
- search_volume（検索ボリューム）の重み付けは？

```python
# 案: キーワードマッチングのスコア計算
seo_score = sum([
    keyword.search_volume * 0.01  # 検索ボリュームに比例？
    for keyword in matched_keywords
])
```

#### 1.3 パーソナライズスコアの協調フィルタリング
**現状**: implicitライブラリのALSを使うとあるが、パラメータが未定義

**質問**:
```python
# これらのパラメータの適切な値は？
ALS_params = {
    'factors': 50,  # 潜在因子の数: 50で良い？
    'regularization': 0.01,  # 正則化: この値で適切？
    'iterations': 15,  # イテレーション数: 十分？
    'alpha': 40  # 信頼度パラメータ: 要調整？
}
```

### 2. カテゴリ分類ルール

#### 2.1 14ニーズカテゴリの判定条件
**現状**: "文章の部分一致"とあるが、具体的なキーワードと優先順位が不明

**質問例（日払い・週払いカテゴリ）**:
```python
# どのフィールドのどのキーワードで判定？
if any(keyword in job.application_name for keyword in ['日払い', '即日払い']):
    categories.append('日払い・週払い')
elif '週払い' in job.salary:  # salaryフィールドも見る？
    categories.append('日払い・週払い')

# 複数カテゴリに該当する場合の優先順位は？
```

#### 2.2 高時給の判定基準
**現状**: "エリア平均より20%以上高い"とあるが、エリア平均の算出方法が不明

**質問**:
- エリアの粒度は？（都道府県？市区町村？）
- 職種別の平均を考慮する？
- 時給以外（日給、月給）の換算方法は？

### 3. 40件選定アルゴリズム

#### 3.1 セクション間の重複処理
**現状**: 6セクション（editorial_picks:5件、top5:5件、regional:10件、nearby:8件、high_income:7件、new:5件）= 合計40件

**質問**:
```python
# editorial_picksやTOP5に入った求人が地域別にも該当する場合は？
# 案A: 重複を許可（同じ求人が複数セクションに登場）
# 案B: 重複を除外（各求人は1セクションのみ） ← 実装済み
# 案C: 優先度順（editorial_picks > TOP5 > regional > nearby > high_income > new）

# 40件に満たない場合の補充ロジックは？
if total_picks < 40:
    # どのセクションから補充？
    # ランダム？スコア順？
```

### 4. メール文面の6セクション切り分けロジック 【新規追加】

#### 4.1 各セクションの選定基準
**現状**: 6セクション構成で実装済み（editorial_picks、top5、regional、nearby、high_income、new）

**質問**:

##### セクション0: 「編集部おすすめの人気バイト」（editorial_picks）【新規追加】
```python
# 選定基準:
# 実装済み: fee × 応募クリック数の上位5件
# 企業の応募促進費用(fee)と実際の人気度を掛け合わせた指標

# 選定条件:
- アクティブな求人のみ
- ユーザーのエリアを考慮した重み付け（市区町村 > 近隣 > 都道府県）
- 2週間以内に応募した企業は除外
```

##### セクション1: 「あなたにおすすめ求人TOP5」（top5）
```python
# 選定基準:
# 実装済み: パーソナライズスコアの上位5件
# 2週間以内に応募した企業(endcl_cd)は除外

# 選定条件:
- アクティブな求人のみ
- 過去の応募履歴を考慮したマッチングスコア
- 地域制限なし（全国から選定）
```

##### セクション2: 「{prefecture}おすすめ求人TOP10」（regional）
```python
# 地域の定義:
# 実装済み: ユーザーの推定都道府県

# 選定基準:
- その都道府県内の全求人から
- 職種マッチングスコアを重視
- editorial_picks、top5との重複を除外
```

##### セクション3: 「{city}周辺のおすすめバイトTOP8」（nearby）
```python
# 近隣の定義:
# 実装済み: 居住市区町村 + 隣接市区町村

# 選定基準:
- 市区町村とその周辺エリアから選定
- 職種マッチングスコアを重視
- 既選択求人との重複を除外
```

##### セクション4: 「高収入・日払いバイトTOP7」（high_income）
```python
# 選定基準:
# 実装済み: 高時給（エリア平均の1.2倍以上）または日払い可能

# 選定条件:
high_income_features = [
    'high_salary',         # エリア平均×1.2以上
    'daily_payment',       # 日払い可能フラグ
]
# 位置情報の重み付け適用
```

##### セクション5: 「新着求人」（new）
```python
# 新着の定義:
# 実装済み: posting_dateが7日以内

# 選定基準:
- 1週間以内に投稿された求人
- スコア上位から5件選定
- 他セクションとの重複除外
```

#### 4.2 セクション間の優先順位と配分
**質問**:
```python
# 固定配分（実装済み）
sections = {
    'editorial_picks': 5,  # 編集部おすすめ（fee×クリック数）
    'top5': 5,            # パーソナライズTOP5
    'regional': 10,       # 地域別（都道府県）
    'nearby': 8,          # 近隣（市区町村周辺）
    'high_income': 7,     # 高収入・日払い
    'new': 5              # 新着求人
}  # 合計40件

# 動的配分？
# 例: 近隣に求人が少ない場合、他セクションから補充？
if len(nearby_jobs) < 10:
    # 不足分をどこから補充？
    # regional から？ benefits から？
```

#### 4.3 表示内容のカスタマイズ
**質問**:
```python
# 各セクションで表示する情報は同じ？異なる？
display_format = {
    'top5': {
        'title': True,        # 求人タイトル
        'salary': True,       # 給与
        'location': True,     # 勤務地
        'features': True,     # 特徴（日払い等）
        'reason': True,       # 推薦理由 ← TOP5のみ？
        'work_hours': True    # 勤務時間
    },
    'regional': {
        'title': True,
        'salary': True,
        'location': False,    # 都道府県は自明なので不要？
        'features': True,
        'reason': False,      # 推薦理由は不要？
        'work_hours': False   # 簡略表示？
    }
    # 他セクションも同様に定義が必要？
}
```

#### 4.4 セクション選定の実行順序
**質問**:
```python
# どの順序で選定する？順序が結果に影響する可能性
# 案A: TOP5 → 地域別 → 近隣 → お得 → 新着
# 案B: 全セクション並列で選定 → 重複調整
# 案C: スコア順に40件選定 → 各セクションに振り分け

# 重複除外の場合の優先順位は？
priority = ['top5', 'nearby', 'regional', 'benefits', 'new']
```

#### 4.5 データ不足時の処理
**質問**:
```python
# 各セクションで必要数に満たない場合
scenarios = {
    'nearby_shortage': {
        # 近隣に5件しかない場合
        'action': '地域別から補充？' or 'そのまま5件で送信？'
    },
    'new_shortage': {
        # 新着が0件の場合
        'action': 'セクション自体を非表示？' or '過去7日に拡大？'
    },
    'total_shortage': {
        # 全体で20件しかない場合
        'action': '20件で送信？' or 'エラー？' or '前日の求人も含める？'
    }
}
```

---

## 🟡 優先度: 中（実装に影響）

### 5. データ管理戦略

#### 5.1 重複求人の処理
**質問**:
- job_idが同じ場合: 更新？スキップ？
- 内容が同じでIDが異なる場合の判定基準は？

```python
# 重複判定のキー
duplicate_key = (company_name, application_name, salary, location)
# これで十分？
```

#### 5.2 データ更新戦略
**質問**:
- 既存求人の更新: 全フィールド上書き？差分更新？
- 削除フラグ: is_activeをfalseにする？物理削除？
- 履歴管理: 変更履歴を保持する？

### 6. エラーハンドリング

#### 6.1 バッチ処理の中断と再開
**質問**:
```python
# 処理が50%で失敗した場合
# 案A: 最初からやり直し
# 案B: チェックポイントから再開
# 案C: 失敗したレコードのみ再処理

# チェックポイントの実装方法は？
checkpoint = {
    'processed_users': [1, 2, 3, ...],
    'failed_users': [101, 102, ...],
    'timestamp': '2025-09-15 06:30:00'
}
```

#### 6.2 メール生成失敗時の処理
**質問**:
- 一部ユーザーのメール生成失敗時、他のユーザーは継続？
- リトライ回数と間隔は？
- 失敗ログの保存先と形式は？

### 7. メール内容の詳細

#### 7.0 メール件名生成AI 【新規追加 - 重要】
**現状**: メールの件名生成方法が未定義

**質問**:
```python
# GPT-5 nano を使用予定だが、以下の詳細が必要
AI_CONFIG = {
    'model': 'GPT-5 nano',  # 確定
    'api_endpoint': '?',     # APIエンドポイント
    'api_key_location': '?', # 環境変数？Supabase？
    'max_tokens': '?',       # トークン制限
    'temperature': '?',      # 創造性パラメータ（0.0-1.0）
    'fallback_strategy': '?' # AI失敗時の対処
}

# プロンプトテンプレート
subject_prompt_template = """
以下のユーザー情報と求人情報から、開封率の高いメール件名を生成してください。
最大50文字、絵文字は使用しない。

ユーザー情報:
- 推定地域: {user_area}
- よく応募するカテゴリ: {frequent_categories}
- 最近の応募履歴: {recent_applications}

今回の推薦内容:
- TOP5求人: {top5_jobs}
- 特徴的な求人: {featured_job}
- 新着数: {new_count}

件名を生成してください:
"""

# 入力データの準備方法
subject_context = {
    'user_area': '?',          # どこから取得？
    'frequent_categories': '?', # user_profilesから？
    'recent_applications': '?', # 何件分？
    'top5_jobs': '?',          # タイトルのみ？詳細も？
    'featured_job': '?',       # どの求人を選ぶ？
    'new_count': '?'           # 新着求人の数
}

# フォールバック戦略
fallback_subjects = [
    '【バイト速報】{user_area}のおすすめ求人{total_count}件',
    '今週の注目バイト！{featured_category}など{total_count}件',
    '{user_area}エリア限定！人気バイト情報'
]

# バッチ処理での利用
batch_strategy = {
    'method': '?',  # 個別生成？バッチ生成？
    'rate_limit': '?',  # API制限は？
    'cache_similar': '?'  # 類似ユーザーで件名を再利用？
}
```

**質問まとめ**:
1. **API設定**: エンドポイント、認証方法、料金体系は？
2. **プロンプト設計**: どの程度の情報を含める？
3. **パフォーマンス**: 10,000件/日の生成は可能？レート制限は？
4. **フォールバック**: AI失敗時はテンプレート使用で良い？
5. **最適化**: 類似ユーザーでの件名再利用は許可？
6. **A/Bテスト**: 件名のバリエーション生成は必要？

#### 7.1 HTMLテンプレート構造
**質問**:
```html
<!-- 基本構造はこれで良い？ -->
<html>
  <head><!-- CSS inline? 外部ファイル? --></head>
  <body>
    <div class="header"><!-- ロゴ、日付 --></div>
    <div class="greeting"><!-- 個人向け挨拶 --></div>
    <div class="section-top5"><!-- ... --></div>
    <div class="section-regional"><!-- ... --></div>
    <!-- 他セクション -->
    <div class="footer"><!-- 配信停止リンク等 --></div>
  </body>
</html>
```

#### 7.2 文字数制限
**質問**:
- 件名: 最大何文字？
- 各求人の説明: 最大何文字？
- 全体のサイズ制限は？（Gmail等の制限考慮）

---

## 🟢 優先度: 低（最適化関連）

### 8. パフォーマンス最適化

#### 8.1 メモリ管理の具体策
**質問**:
```python
# pandas のメモリ削減手法の優先順位は？
optimizations = [
    'category型への変換',
    'float64→float32への変換',
    'chunksize指定での読み込み',
    '不要カラムの即座削除'
]
```

#### 8.2 キャッシュ戦略
**質問**:
- Redis使用？Supabaseのキャッシュ機能？
- キャッシュの有効期限は？
- キャッシュキーの設計は？

### 9. モニタリングUI

#### 9.1 認証方式
**質問**:
- 管理者のみアクセス？
- Supabase Auth使用？独自認証？
- APIキー認証？JWT？

#### 9.2 リアルタイム更新
**質問**:
- WebSocket使用？
- ポーリング間隔は？（1秒？5秒？）
- Supabaseのリアルタイム機能を使う？

### 10. テストデータ

#### 10.1 テストデータ生成戦略
**質問**:
```python
# 10万件の求人データ生成方法
# 案A: Faker使用でランダム生成
# 案B: 本番データのサブセット使用
# 案C: 手動で作成した1000件を複製

# ユーザー行動のシミュレーション
# どの程度リアルなパターンが必要？
```

---

## 📝 推奨解決アプローチ

### ステップ1: 技術的決定（すぐに決める）
1. スコアリング計算式の確定
2. カテゴリ分類ルールの明文化
3. 40件選定アルゴリズムの詳細

### ステップ2: 実装ガイドライン作成
```markdown
# algorithms.md を作成して以下を定義
- 各スコアの計算式（数式とPythonコード）
- カテゴリ判定のフローチャート
- マッチングアルゴリズムの疑似コード
```

### ステップ3: エラー処理方針
```markdown
# error-handling.md を作成して以下を定義
- リトライ戦略（回数、間隔、条件）
- ログフォーマット
- アラート条件
```

---

## 🎯 次のアクション

### 即座に必要な決定（実装開始前）
1. **基礎スコア計算式**: □ 確定
2. **カテゴリ判定キーワード**: □ リスト作成
3. **40件選定の重複処理**: □ 方針決定

### 実装と並行して決定可能
4. エラーハンドリング詳細
5. キャッシュ戦略
6. テストデータ生成方法

### 回答テンプレート
```yaml
# 以下の形式で回答いただけると実装がスムーズです

スコアリング:
  基礎スコア:
    時給の重み: 0.4
    アクセスの重み: 0.2
    福利厚生の重み: 0.2
    人気度の重み: 0.2
    正規化方法: min-max  # または z-score

カテゴリ分類:
  日払い・週払い:
    対象フィールド: [application_name, salary, features]
    キーワード: ['日払い', '即日払い', '週払い']
    優先度: 1

40件選定:
  重複処理: 除外  # または 許可
  補充ロジック: スコア順
  最低保証: 20件  # 40件に満たない場合の最低数
```

---

## ✅ システム開発可能性の評価

**結論**: **開発可能だが、上記の🔴高優先度項目の決定が必要**

### 強み
- アーキテクチャは明確
- 技術スタックは確定
- タスク分解は適切
- TDD方法論で品質確保

### 要改善点
- アルゴリズムの詳細定義
- エラー処理の具体化
- データ管理方針の明確化

上記の質問に回答いただければ、tasks.mdの実行を開始し、確実にシステムを完成させることができます。

---

**このドキュメントは生きたドキュメントです。決定事項は随時更新してください。**