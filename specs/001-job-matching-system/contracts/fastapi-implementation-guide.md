# FastAPIå®Ÿè£…ã‚¬ã‚¤ãƒ‰ - ãƒã‚¤ãƒˆæ±‚äººãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ 

## ğŸ“‹ æ¦‚è¦

ã“ã®ãƒ‰ã‚­ãƒ¥ãƒ¡ãƒ³ãƒˆã¯ã€è©³ç´°APIä»•æ§˜ï¼ˆ`detailed-api-spec.yaml`ï¼‰ã‚’FastAPIã§å®Ÿè£…ã™ã‚‹ãŸã‚ã®å…·ä½“çš„ãªã‚¬ã‚¤ãƒ‰ã§ã™ã€‚

---

## ğŸ—ï¸ ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ§‹é€ 

```
job_matching_api/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ main.py                    # FastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ config.py                  # è¨­å®šç®¡ç†
â”‚   â”œâ”€â”€ database.py                # DBæ¥ç¶šè¨­å®š
â”‚   â”œâ”€â”€ dependencies.py            # ä¾å­˜é–¢ä¿‚
â”‚   â”œâ”€â”€ middleware.py              # ãƒŸãƒ‰ãƒ«ã‚¦ã‚§ã‚¢
â”‚   â”œâ”€â”€ models/                    # SQLAlchemyãƒ¢ãƒ‡ãƒ«
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ job.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ matching.py
â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚   â”‚   â””â”€â”€ monitoring.py
â”‚   â”œâ”€â”€ schemas/                   # Pydanticã‚¹ã‚­ãƒ¼ãƒ
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ job.py
â”‚   â”‚   â”œâ”€â”€ user.py
â”‚   â”‚   â”œâ”€â”€ matching.py
â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚   â”‚   â”œâ”€â”€ monitoring.py
â”‚   â”‚   â””â”€â”€ common.py
â”‚   â”œâ”€â”€ api/                       # APIãƒ«ãƒ¼ã‚¿ãƒ¼
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ v2/
â”‚   â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”‚   â”œâ”€â”€ jobs.py
â”‚   â”‚   â”‚   â”œâ”€â”€ users.py
â”‚   â”‚   â”‚   â”œâ”€â”€ matching.py
â”‚   â”‚   â”‚   â”œâ”€â”€ batch.py
â”‚   â”‚   â”‚   â”œâ”€â”€ monitoring.py
â”‚   â”‚   â”‚   â””â”€â”€ email.py
â”‚   â”œâ”€â”€ services/                  # ãƒ“ã‚¸ãƒã‚¹ãƒ­ã‚¸ãƒƒã‚¯
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ job_service.py
â”‚   â”‚   â”œâ”€â”€ user_service.py
â”‚   â”‚   â”œâ”€â”€ matching_service.py
â”‚   â”‚   â”œâ”€â”€ batch_service.py
â”‚   â”‚   â”œâ”€â”€ email_service.py
â”‚   â”‚   â””â”€â”€ monitoring_service.py
â”‚   â”œâ”€â”€ core/                      # ã‚³ã‚¢æ©Ÿèƒ½
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ security.py
â”‚   â”‚   â”œâ”€â”€ logging.py
â”‚   â”‚   â”œâ”€â”€ exceptions.py
â”‚   â”‚   â””â”€â”€ utils.py
â”‚   â””â”€â”€ workers/                   # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ãƒ¯ãƒ¼ã‚«ãƒ¼
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ scoring_worker.py
â”‚       â”œâ”€â”€ matching_worker.py
â”‚       â””â”€â”€ email_worker.py
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ docker-compose.yml
â”œâ”€â”€ Dockerfile
â””â”€â”€ tests/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ conftest.py
    â”œâ”€â”€ test_jobs.py
    â”œâ”€â”€ test_users.py
    â”œâ”€â”€ test_matching.py
    â”œâ”€â”€ test_batch.py
    â””â”€â”€ test_monitoring.py
```

---

## ğŸš€ ã‚»ãƒƒãƒˆã‚¢ãƒƒãƒ—ãƒ»è¨­å®š

### requirements.txt
```txt
fastapi==0.104.1
uvicorn[standard]==0.24.0
sqlalchemy==2.0.23
alembic==1.12.1
pydantic[email]==2.5.0
python-multipart==0.0.6
aiofiles==23.2.1
aioredis==2.0.1
celery==5.3.4
redis==5.0.1
asyncpg==0.29.0
pandas==2.1.3
scikit-learn==1.3.2
openai==1.3.7
httpx==0.25.2
pytest==7.4.3
pytest-asyncio==0.21.1
python-jose[cryptography]==3.3.0
passlib[bcrypt]==1.7.4
python-dotenv==1.0.0
loguru==0.7.2
prometheus-client==0.19.0
```

### app/config.py
```python
from pydantic_settings import BaseSettings
from typing import Optional
import os

class Settings(BaseSettings):
    # Database
    database_url: str = "postgresql+asyncpg://user:pass@localhost/jobmatching"
    database_pool_size: int = 20
    database_max_overflow: int = 30

    # Redis
    redis_url: str = "redis://localhost:6379"

    # API Keys
    openai_api_key: str
    supabase_url: str
    supabase_key: str

    # Security
    secret_key: str
    algorithm: str = "HS256"
    access_token_expire_minutes: int = 30
    api_key_header: str = "X-API-Key"

    # Batch Processing
    celery_broker_url: str = "redis://localhost:6379/1"
    celery_result_backend: str = "redis://localhost:6379/2"
    max_batch_workers: int = 8

    # Performance
    default_page_size: int = 50
    max_page_size: int = 1000
    request_timeout: int = 30

    # Monitoring
    log_level: str = "INFO"
    enable_metrics: bool = True

    # Email Generation
    email_batch_size: int = 100
    max_jobs_per_section: int = 10

    class Config:
        env_file = ".env"

settings = Settings()
```

---

## ğŸ›ï¸ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«ä¾‹

### app/models/job.py
```python
from sqlalchemy import Column, Integer, String, Text, Float, DateTime, Boolean, ARRAY
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.sql import func
from enum import Enum

Base = declarative_base()

class JobStatus(str, Enum):
    DRAFT = "draft"
    ACTIVE = "active"
    PAUSED = "paused"
    EXPIRED = "expired"
    DELETED = "deleted"

class OccupationCategory(str, Enum):
    RESTAURANT = "restaurant"
    RETAIL = "retail"
    OFFICE = "office"
    LOGISTICS = "logistics"
    EDUCATION = "education"
    MEDICAL = "medical"
    CONSTRUCTION = "construction"
    MANUFACTURING = "manufacturing"
    IT = "it"
    SERVICE = "service"
    CREATIVE = "creative"
    OTHER = "other"

class Job(Base):
    __tablename__ = "jobs"

    id = Column(Integer, primary_key=True, index=True)
    external_id = Column(String(255), unique=True, index=True)
    company_name = Column(String(100), nullable=False, index=True)
    title = Column(String(200), nullable=False, index=True)
    description = Column(Text)

    # Salary
    salary_min = Column(Integer)
    salary_max = Column(Integer)

    # Location
    location = Column(String(200), index=True)
    prefecture = Column(String(50), index=True)
    city = Column(String(100), index=True)
    nearest_station = Column(String(100))

    # Work details
    work_hours = Column(String(200))
    work_days = Column(String(200))
    features = Column(ARRAY(String))

    # Categories
    occupation_category = Column(String(50), nullable=False, index=True)
    needs_categories = Column(ARRAY(String))

    # Scores
    basic_score = Column(Float, default=0.0, index=True)
    seo_score = Column(Float, default=0.0, index=True)
    personalized_score = Column(Float, default=0.0, index=True)
    combined_score = Column(Float, default=0.0, index=True)

    # Status
    status = Column(String(20), default=JobStatus.ACTIVE, index=True)

    # URLs
    url = Column(String(500))
    application_url = Column(String(500))

    # Timestamps
    created_at = Column(DateTime, server_default=func.now(), index=True)
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())
    expires_at = Column(DateTime, index=True)
```

### app/models/user.py
```python
from sqlalchemy import Column, Integer, String, Boolean, DateTime, Float, JSON
from sqlalchemy.sql import func
from .job import Base
from enum import Enum

class UserStatus(str, Enum):
    ACTIVE = "active"
    INACTIVE = "inactive"
    SUSPENDED = "suspended"
    DELETED = "deleted"

class Gender(str, Enum):
    MALE = "male"
    FEMALE = "female"
    OTHER = "other"
    NOT_SPECIFIED = "not_specified"

class User(Base):
    __tablename__ = "users"

    id = Column(Integer, primary_key=True, index=True)
    email = Column(String(255), unique=True, index=True, nullable=False)
    name = Column(String(100))
    age = Column(Integer)
    gender = Column(String(20))

    # Location
    location = Column(JSON)  # {"prefecture": "æ±äº¬éƒ½", "city": "æ¸‹è°·åŒº", "address": "..."}

    # Status
    status = Column(String(20), default=UserStatus.ACTIVE, index=True)
    email_verified = Column(Boolean, default=False)

    # Engagement
    engagement_score = Column(Float, default=0.0, index=True)
    last_login = Column(DateTime)

    # Timestamps
    created_at = Column(DateTime, server_default=func.now(), index=True)
    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())

class UserProfile(Base):
    __tablename__ = "user_profiles"

    id = Column(Integer, primary_key=True)
    user_id = Column(Integer, nullable=False, index=True)

    # Work preferences
    work_preferences = Column(JSON)
    # Example: {
    #   "preferred_occupations": ["restaurant", "retail"],
    #   "preferred_locations": ["æ±äº¬éƒ½", "ç¥å¥ˆå·çœŒ"],
    #   "salary_expectation": {"min": 1200, "max": 2000},
    #   "work_style": ["part_time", "flexible"]
    # }

    # Experience
    experience = Column(JSON)
    # Example: {
    #   "work_history": [
    #     {"occupation": "restaurant", "duration_months": 12, "skills": ["æ¥å®¢", "èª¿ç†è£œåŠ©"]}
    #   ],
    #   "education": "university"
    # }

    # Personal info
    personal_info = Column(JSON)
    # Example: {
    #   "transportation": ["public_transport", "bicycle"],
    #   "availability": {
    #     "weekdays": true, "weekends": false,
    #     "mornings": true, "afternoons": true, "evenings": false, "nights": false
    #   }
    # }

    updated_at = Column(DateTime, server_default=func.now(), onupdate=func.now())

class UserBehaviorLog(Base):
    __tablename__ = "user_behavior_logs"

    id = Column(Integer, primary_key=True, index=True)
    user_id = Column(Integer, nullable=False, index=True)
    action_type = Column(String(50), nullable=False, index=True)
    target_id = Column(Integer)
    target_type = Column(String(50))
    metadata = Column(JSON)
    session_id = Column(String(255), index=True)
    ip_address = Column(String(45))
    user_agent = Column(Text)
    timestamp = Column(DateTime, server_default=func.now(), index=True)
```

---

## ğŸ”Œ APIãƒ«ãƒ¼ã‚¿ãƒ¼å®Ÿè£…ä¾‹

### app/api/v2/jobs.py
```python
from fastapi import APIRouter, Depends, HTTPException, Query, BackgroundTasks
from typing import List, Optional
from sqlalchemy.orm import Session
from ...database import get_db
from ...schemas.job import (
    Job, JobCreateRequest, JobUpdateRequest, JobListResponse,
    JobSearchRequest, JobSearchResponse
)
from ...services.job_service import JobService
from ...core.security import get_api_key
from ...core.exceptions import JobNotFoundError

router = APIRouter(prefix="/jobs", tags=["Jobs"])

@router.get("/", response_model=JobListResponse)
async def get_jobs(
    page: int = Query(1, ge=1),
    limit: int = Query(50, ge=1, le=1000),
    keyword: Optional[str] = Query(None, max_length=100),
    location: Optional[str] = Query(None),
    salary_min: Optional[int] = Query(None, ge=0),
    salary_max: Optional[int] = Query(None, ge=0),
    occupation_categories: Optional[List[str]] = Query(None),
    needs_categories: Optional[List[str]] = Query(None),
    status: str = Query("active"),
    sort_by: str = Query("updated_at"),
    sort_order: str = Query("desc"),
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººä¸€è¦§å–å¾—"""
    service = JobService(db)

    filters = {
        "keyword": keyword,
        "location": location,
        "salary_min": salary_min,
        "salary_max": salary_max,
        "occupation_categories": occupation_categories,
        "needs_categories": needs_categories,
        "status": status
    }

    result = await service.get_jobs(
        page=page,
        limit=limit,
        filters=filters,
        sort_by=sort_by,
        sort_order=sort_order
    )

    return result

@router.post("/", response_model=Job, status_code=201)
async def create_job(
    job_data: JobCreateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººä½œæˆ"""
    service = JobService(db)

    job = await service.create_job(job_data)

    # ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã§ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ã¨ã‚«ãƒ†ã‚´ãƒªåˆ†é¡ã‚’å®Ÿè¡Œ
    background_tasks.add_task(service.calculate_scores, job.id)
    background_tasks.add_task(service.categorize_job, job.id)

    return job

@router.get("/{job_id}", response_model=Job)
async def get_job(
    job_id: int,
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººè©³ç´°å–å¾—"""
    service = JobService(db)

    job = await service.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    return job

@router.put("/{job_id}", response_model=Job)
async def update_job(
    job_id: int,
    job_data: JobUpdateRequest,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººæ›´æ–°"""
    service = JobService(db)

    job = await service.update_job(job_id, job_data)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    # ã‚¹ã‚³ã‚¢å†è¨ˆç®—
    background_tasks.add_task(service.calculate_scores, job.id)

    return job

@router.delete("/{job_id}", status_code=204)
async def delete_job(
    job_id: int,
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººå‰Šé™¤ï¼ˆè«–ç†å‰Šé™¤ï¼‰"""
    service = JobService(db)

    success = await service.delete_job(job_id)
    if not success:
        raise HTTPException(status_code=404, detail="Job not found")

@router.post("/search", response_model=JobSearchResponse)
async def search_jobs(
    search_request: JobSearchRequest,
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """é«˜åº¦ãªæ±‚äººæ¤œç´¢"""
    service = JobService(db)

    result = await service.search_jobs(search_request)
    return result

@router.post("/bulk")
async def bulk_jobs(
    # ãƒãƒ«ãƒãƒ‘ãƒ¼ãƒˆ/JSONã§ã®ä¸€æ‹¬å‡¦ç†å®Ÿè£…
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººä¸€æ‹¬å‡¦ç†"""
    # å®Ÿè£…è©³ç´°ã¯çœç•¥
    pass

@router.post("/{job_id}/scoring")
async def score_job(
    job_id: int,
    background_tasks: BackgroundTasks,
    db: Session = Depends(get_db),
    api_key: str = Depends(get_api_key)
):
    """æ±‚äººã‚¹ã‚³ã‚¢å†è¨ˆç®—"""
    service = JobService(db)

    job = await service.get_job(job_id)
    if not job:
        raise HTTPException(status_code=404, detail="Job not found")

    background_tasks.add_task(service.calculate_scores, job_id)

    return {"message": "Scoring job started", "job_id": job_id}
```

### app/services/job_service.py
```python
from sqlalchemy.orm import Session
from sqlalchemy import and_, or_, func
from typing import List, Optional, Dict, Any
from ..models.job import Job, JobStatus
from ..schemas.job import JobCreateRequest, JobUpdateRequest, JobSearchRequest
from ..core.exceptions import JobNotFoundError
import logging

logger = logging.getLogger(__name__)

class JobService:
    def __init__(self, db: Session):
        self.db = db

    async def get_jobs(
        self,
        page: int,
        limit: int,
        filters: Dict[str, Any],
        sort_by: str,
        sort_order: str
    ):
        """æ±‚äººä¸€è¦§å–å¾—"""
        query = self.db.query(Job)

        # ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        if filters.get("keyword"):
            keyword = f"%{filters['keyword']}%"
            query = query.filter(
                or_(
                    Job.title.ilike(keyword),
                    Job.company_name.ilike(keyword),
                    Job.description.ilike(keyword)
                )
            )

        if filters.get("location"):
            location = f"%{filters['location']}%"
            query = query.filter(Job.location.ilike(location))

        if filters.get("salary_min"):
            query = query.filter(Job.salary_min >= filters["salary_min"])

        if filters.get("salary_max"):
            query = query.filter(Job.salary_max <= filters["salary_max"])

        if filters.get("occupation_categories"):
            query = query.filter(Job.occupation_category.in_(filters["occupation_categories"]))

        if filters.get("status"):
            query = query.filter(Job.status == filters["status"])

        # ã‚½ãƒ¼ãƒˆ
        sort_column = getattr(Job, sort_by, Job.updated_at)
        if sort_order == "desc":
            query = query.order_by(sort_column.desc())
        else:
            query = query.order_by(sort_column.asc())

        # ãƒšãƒ¼ã‚¸ãƒãƒ¼ã‚·ãƒ§ãƒ³
        total = query.count()
        offset = (page - 1) * limit
        jobs = query.offset(offset).limit(limit).all()

        return {
            "jobs": jobs,
            "pagination": {
                "page": page,
                "limit": limit,
                "total_items": total,
                "total_pages": (total + limit - 1) // limit,
                "has_next": page * limit < total,
                "has_prev": page > 1
            }
        }

    async def create_job(self, job_data: JobCreateRequest) -> Job:
        """æ±‚äººä½œæˆ"""
        job = Job(**job_data.dict())
        self.db.add(job)
        self.db.commit()
        self.db.refresh(job)

        logger.info(f"Created job {job.id}: {job.title}")
        return job

    async def get_job(self, job_id: int) -> Optional[Job]:
        """æ±‚äººè©³ç´°å–å¾—"""
        return self.db.query(Job).filter(Job.id == job_id).first()

    async def update_job(self, job_id: int, job_data: JobUpdateRequest) -> Optional[Job]:
        """æ±‚äººæ›´æ–°"""
        job = self.db.query(Job).filter(Job.id == job_id).first()
        if not job:
            return None

        for field, value in job_data.dict(exclude_unset=True).items():
            setattr(job, field, value)

        self.db.commit()
        self.db.refresh(job)

        logger.info(f"Updated job {job_id}")
        return job

    async def delete_job(self, job_id: int) -> bool:
        """æ±‚äººå‰Šé™¤ï¼ˆè«–ç†å‰Šé™¤ï¼‰"""
        job = self.db.query(Job).filter(Job.id == job_id).first()
        if not job:
            return False

        job.status = JobStatus.DELETED
        self.db.commit()

        logger.info(f"Deleted job {job_id}")
        return True

    async def calculate_scores(self, job_id: int):
        """æ±‚äººã‚¹ã‚³ã‚¢è¨ˆç®—"""
        job = await self.get_job(job_id)
        if not job:
            return

        # åŸºç¤ã‚¹ã‚³ã‚¢è¨ˆç®—
        basic_score = self._calculate_basic_score(job)

        # SEOã‚¹ã‚³ã‚¢è¨ˆç®—
        seo_score = self._calculate_seo_score(job)

        # ãƒ‘ãƒ¼ã‚½ãƒŠãƒ©ã‚¤ã‚ºã‚¹ã‚³ã‚¢è¨ˆç®—ï¼ˆå®Ÿè£…çœç•¥ï¼‰
        personalized_score = 0.0

        # çµ±åˆã‚¹ã‚³ã‚¢è¨ˆç®—
        combined_score = (basic_score * 0.4 + seo_score * 0.3 + personalized_score * 0.3)

        # DBæ›´æ–°
        job.basic_score = basic_score
        job.seo_score = seo_score
        job.personalized_score = personalized_score
        job.combined_score = combined_score

        self.db.commit()
        logger.info(f"Calculated scores for job {job_id}: basic={basic_score:.2f}, seo={seo_score:.2f}")

    def _calculate_basic_score(self, job: Job) -> float:
        """åŸºç¤ã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 0.0

        # ã‚¿ã‚¤ãƒˆãƒ«ã®é•·ã•
        if job.title and 10 <= len(job.title) <= 30:
            score += 20

        # èª¬æ˜ã®å……å®Ÿåº¦
        if job.description and len(job.description) >= 100:
            score += 15

        # çµ¦ä¸æƒ…å ±ã®æœ‰ç„¡
        if job.salary_min and job.salary_max:
            score += 25

        # å‹¤å‹™åœ°æƒ…å ±ã®è©³ç´°åº¦
        if job.prefecture and job.city:
            score += 20

        # æœ€å¯„ã‚Šé§…æƒ…å ±
        if job.nearest_station:
            score += 10

        # ç‰¹å¾´ã®æ•°
        if job.features:
            score += min(len(job.features) * 2, 10)

        return min(score, 100.0)

    def _calculate_seo_score(self, job: Job) -> float:
        """SEOã‚¹ã‚³ã‚¢è¨ˆç®—"""
        score = 0.0

        # ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰å¯†åº¦ãƒã‚§ãƒƒã‚¯ï¼ˆç°¡æ˜“ç‰ˆï¼‰
        if job.title and job.description:
            title_words = set(job.title.lower().split())
            desc_words = job.description.lower().split()

            # ã‚¿ã‚¤ãƒˆãƒ«ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒèª¬æ˜æ–‡ã«ã‚‚å«ã¾ã‚Œã‚‹
            for word in title_words:
                if word in desc_words:
                    score += 5

        # URLæ§‹é€ 
        if job.url and 'https' in job.url:
            score += 10

        # åœ°åŸŸã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰
        if job.location and any(region in job.location for region in ['æ±äº¬', 'å¤§é˜ª', 'åå¤å±‹']):
            score += 15

        return min(score, 100.0)

    async def search_jobs(self, search_request: JobSearchRequest):
        """é«˜åº¦æ¤œç´¢"""
        # Elasticsearchç­‰ã®å®Ÿè£…ãŒç†æƒ³ã ãŒã€ç°¡æ˜“ç‰ˆã‚’PostgreSQLã§å®Ÿè£…
        query = self.db.query(Job)

        # å…¨æ–‡æ¤œç´¢ï¼ˆPostgreSQLã®full-text searchã‚’ä½¿ç”¨ï¼‰
        if search_request.query:
            # å®Ÿéš›ã®å®Ÿè£…ã§ã¯å…¨æ–‡æ¤œç´¢ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä½¿ç”¨
            pass

        # åœ°ç†çš„æ¤œç´¢
        if search_request.location and search_request.location.point:
            # PostGISã‚’ä½¿ç”¨ã—ãŸåœ°ç†çš„æ¤œç´¢
            pass

        # ãã®ä»–ã®ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°å®Ÿè£…

        return {"jobs": [], "pagination": {}, "search_meta": {}}
```

---

## ğŸ” ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£å®Ÿè£…

### app/core/security.py
```python
from fastapi import HTTPException, Depends, status
from fastapi.security import HTTPBearer, HTTPAuthorizationCredentials
from jose import JWTError, jwt
from datetime import datetime, timedelta
from ..config import settings
import hashlib
import secrets

security = HTTPBearer(auto_error=False)

# APIã‚­ãƒ¼èªè¨¼
async def get_api_key(authorization: HTTPAuthorizationCredentials = Depends(security)):
    """APIã‚­ãƒ¼èªè¨¼"""
    if authorization is None:
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="API key required",
            headers={"WWW-Authenticate": "Bearer"},
        )

    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§APIã‚­ãƒ¼ã‚’æ¤œè¨¼
    api_key = authorization.credentials
    if not validate_api_key(api_key):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Invalid API key",
            headers={"WWW-Authenticate": "Bearer"},
        )

    return api_key

def validate_api_key(api_key: str) -> bool:
    """APIã‚­ãƒ¼æ¤œè¨¼"""
    # å®Ÿéš›ã®å®Ÿè£…ã§ã¯ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã§APIã‚­ãƒ¼ã‚’æ¤œè¨¼
    # ãƒãƒƒã‚·ãƒ¥åŒ–ã•ã‚ŒãŸAPIã‚­ãƒ¼ã¨ã®æ¯”è¼ƒç­‰
    return len(api_key) >= 32  # ä»®ã®å®Ÿè£…

def create_access_token(data: dict, expires_delta: timedelta = None):
    """JWTãƒˆãƒ¼ã‚¯ãƒ³ä½œæˆ"""
    to_encode = data.copy()
    if expires_delta:
        expire = datetime.utcnow() + expires_delta
    else:
        expire = datetime.utcnow() + timedelta(minutes=15)

    to_encode.update({"exp": expire})
    encoded_jwt = jwt.encode(to_encode, settings.secret_key, algorithm=settings.algorithm)
    return encoded_jwt

async def get_current_user(token: str = Depends(security)):
    """JWTèªè¨¼"""
    credentials_exception = HTTPException(
        status_code=status.HTTP_401_UNAUTHORIZED,
        detail="Could not validate credentials",
        headers={"WWW-Authenticate": "Bearer"},
    )

    try:
        payload = jwt.decode(token.credentials, settings.secret_key, algorithms=[settings.algorithm])
        user_id: str = payload.get("sub")
        if user_id is None:
            raise credentials_exception
    except JWTError:
        raise credentials_exception

    # ãƒ¦ãƒ¼ã‚¶ãƒ¼å–å¾—ãƒ­ã‚¸ãƒƒã‚¯
    return user_id
```

---

## ğŸ”„ ãƒãƒƒã‚¯ã‚°ãƒ©ã‚¦ãƒ³ãƒ‰ã‚¿ã‚¹ã‚¯

### app/workers/matching_worker.py
```python
from celery import Celery
from sqlalchemy.orm import Session
from ..database import get_db
from ..services.matching_service import MatchingService
from ..config import settings
import logging

logger = logging.getLogger(__name__)

celery_app = Celery(
    "job_matching",
    broker=settings.celery_broker_url,
    backend=settings.celery_result_backend
)

@celery_app.task(bind=True, max_retries=3)
def process_user_matching(self, user_id: int, batch_date: str):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†"""
    try:
        db = next(get_db())
        service = MatchingService(db)

        result = service.generate_recommendations(user_id, batch_date)

        logger.info(f"Completed matching for user {user_id}, generated {len(result)} recommendations")
        return result

    except Exception as exc:
        logger.error(f"Matching failed for user {user_id}: {exc}")
        raise self.retry(exc=exc, countdown=60)

@celery_app.task(bind=True)
def batch_scoring(self, job_ids: list = None):
    """ãƒãƒƒãƒã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°"""
    try:
        db = next(get_db())
        from ..services.job_service import JobService

        service = JobService(db)

        if job_ids is None:
            # å…¨æ±‚äººã‚’å¯¾è±¡
            jobs = db.query(Job).filter(Job.status == "active").all()
            job_ids = [job.id for job in jobs]

        for job_id in job_ids:
            service.calculate_scores(job_id)

        logger.info(f"Completed batch scoring for {len(job_ids)} jobs")
        return {"processed": len(job_ids)}

    except Exception as exc:
        logger.error(f"Batch scoring failed: {exc}")
        raise
```

---

## ğŸ“Š ãƒ¢ãƒ‹ã‚¿ãƒªãƒ³ã‚°ãƒ»ãƒ­ã‚°

### app/core/logging.py
```python
import logging
import sys
from loguru import logger
from ..config import settings

class InterceptHandler(logging.Handler):
    def emit(self, record):
        # Get corresponding Loguru level if it exists
        try:
            level = logger.level(record.levelname).name
        except ValueError:
            level = record.levelno

        # Find caller from where originated the logged message
        frame, depth = logging.currentframe(), 2
        while frame.f_code.co_filename == logging.__file__:
            frame = frame.f_back
            depth += 1

        logger.opt(depth=depth, exception=record.exc_info).log(level, record.getMessage())

def setup_logging():
    """ãƒ­ã‚°è¨­å®š"""
    # Remove default handlers
    logger.remove()

    # Add custom handler
    logger.add(
        sys.stdout,
        format="<green>{time:YYYY-MM-DD HH:mm:ss.SSS}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
        level=settings.log_level
    )

    # Add file handler
    logger.add(
        "logs/app.log",
        rotation="1 day",
        retention="30 days",
        format="{time:YYYY-MM-DD HH:mm:ss.SSS} | {level: <8} | {name}:{function}:{line} - {message}",
        level="INFO"
    )

    # Intercept standard logging
    logging.basicConfig(handlers=[InterceptHandler()], level=0, force=True)
```

### app/middleware.py
```python
from fastapi import Request, Response
from fastapi.middleware.base import BaseHTTPMiddleware
import time
import uuid
from loguru import logger

class LoggingMiddleware(BaseHTTPMiddleware):
    async def dispatch(self, request: Request, call_next):
        # Generate trace ID
        trace_id = str(uuid.uuid4())
        request.state.trace_id = trace_id

        start_time = time.time()

        # Log request
        logger.info(
            f"Request started",
            extra={
                "trace_id": trace_id,
                "method": request.method,
                "url": str(request.url),
                "client_ip": request.client.host
            }
        )

        response = await call_next(request)

        process_time = time.time() - start_time

        # Log response
        logger.info(
            f"Request completed",
            extra={
                "trace_id": trace_id,
                "status_code": response.status_code,
                "process_time": process_time
            }
        )

        response.headers["X-Trace-ID"] = trace_id
        response.headers["X-Process-Time"] = str(process_time)

        return response

class RateLimitMiddleware(BaseHTTPMiddleware):
    def __init__(self, app, calls: int = 100, period: int = 60):
        super().__init__(app)
        self.calls = calls
        self.period = period
        self.clients = {}

    async def dispatch(self, request: Request, call_next):
        client_ip = request.client.host
        now = time.time()

        # Clean old entries
        self.clients = {
            ip: timestamps for ip, timestamps in self.clients.items()
            if any(ts > now - self.period for ts in timestamps)
        }

        # Check rate limit
        if client_ip in self.clients:
            recent_calls = [ts for ts in self.clients[client_ip] if ts > now - self.period]
            if len(recent_calls) >= self.calls:
                return Response(
                    content="Rate limit exceeded",
                    status_code=429,
                    headers={"Retry-After": str(self.period)}
                )
            self.clients[client_ip] = recent_calls + [now]
        else:
            self.clients[client_ip] = [now]

        return await call_next(request)
```

---

## ğŸ§ª ãƒ†ã‚¹ãƒˆå®Ÿè£…ä¾‹

### tests/test_jobs.py
```python
import pytest
from fastapi.testclient import TestClient
from sqlalchemy import create_engine
from sqlalchemy.orm import sessionmaker
from app.main import app
from app.database import get_db, Base

# Test database
SQLALCHEMY_DATABASE_URL = "sqlite:///./test.db"
engine = create_engine(SQLALCHEMY_DATABASE_URL, connect_args={"check_same_thread": False})
TestingSessionLocal = sessionmaker(autocommit=False, autoflush=False, bind=engine)

Base.metadata.create_all(bind=engine)

def override_get_db():
    try:
        db = TestingSessionLocal()
        yield db
    finally:
        db.close()

app.dependency_overrides[get_db] = override_get_db

client = TestClient(app)

@pytest.fixture
def test_job_data():
    return {
        "company_name": "ãƒ†ã‚¹ãƒˆæ ªå¼ä¼šç¤¾",
        "title": "ã‚¢ãƒ«ãƒã‚¤ãƒˆã‚¹ã‚¿ãƒƒãƒ•å‹Ÿé›†",
        "description": "ã‚«ãƒ•ã‚§ã§ã®ã‚¢ãƒ«ãƒã‚¤ãƒˆã‚¹ã‚¿ãƒƒãƒ•ã‚’å‹Ÿé›†ã—ã¦ã„ã¾ã™ã€‚",
        "salary_min": 1200,
        "salary_max": 1500,
        "location": "æ±äº¬éƒ½æ¸‹è°·åŒº",
        "occupation_category": "restaurant"
    }

def test_create_job(test_job_data):
    """æ±‚äººä½œæˆãƒ†ã‚¹ãƒˆ"""
    response = client.post(
        "/api/v2/jobs/",
        json=test_job_data,
        headers={"X-API-Key": "test-api-key"}
    )
    assert response.status_code == 201
    data = response.json()
    assert data["company_name"] == test_job_data["company_name"]
    assert data["title"] == test_job_data["title"]

def test_get_jobs():
    """æ±‚äººä¸€è¦§å–å¾—ãƒ†ã‚¹ãƒˆ"""
    response = client.get(
        "/api/v2/jobs/",
        headers={"X-API-Key": "test-api-key"}
    )
    assert response.status_code == 200
    data = response.json()
    assert "jobs" in data
    assert "pagination" in data

def test_search_jobs():
    """æ±‚äººæ¤œç´¢ãƒ†ã‚¹ãƒˆ"""
    search_data = {
        "query": "ã‚¢ãƒ«ãƒã‚¤ãƒˆ",
        "page": 1,
        "limit": 10
    }
    response = client.post(
        "/api/v2/jobs/search",
        json=search_data,
        headers={"X-API-Key": "test-api-key"}
    )
    assert response.status_code == 200

@pytest.mark.asyncio
async def test_job_scoring():
    """æ±‚äººã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ã‚¹ãƒˆ"""
    # æ±‚äººä½œæˆå¾Œã€ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°å‡¦ç†ã‚’ãƒ†ã‚¹ãƒˆ
    pass
```

---

## ğŸš€ ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ

### Dockerfile
```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install system dependencies
RUN apt-get update && apt-get install -y \
    gcc \
    postgresql-client \
    && rm -rf /var/lib/apt/lists/*

# Install Python dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Copy application
COPY app/ app/
COPY alembic/ alembic/
COPY alembic.ini .

# Run migrations and start server
CMD ["sh", "-c", "alembic upgrade head && uvicorn app.main:app --host 0.0.0.0 --port 8000"]
```

### docker-compose.yml
```yaml
version: '3.8'

services:
  api:
    build: .
    ports:
      - "8000:8000"
    environment:
      - DATABASE_URL=postgresql+asyncpg://postgres:password@postgres:5432/jobmatching
      - REDIS_URL=redis://redis:6379
      - OPENAI_API_KEY=${OPENAI_API_KEY}
    depends_on:
      - postgres
      - redis
    volumes:
      - ./logs:/app/logs

  postgres:
    image: postgres:15
    environment:
      - POSTGRES_DB=jobmatching
      - POSTGRES_USER=postgres
      - POSTGRES_PASSWORD=password
    volumes:
      - postgres_data:/var/lib/postgresql/data
    ports:
      - "5432:5432"

  redis:
    image: redis:7
    ports:
      - "6379:6379"

  celery:
    build: .
    command: celery -A app.workers.matching_worker worker --loglevel=info
    environment:
      - DATABASE_URL=postgresql+asyncpg://postgres:password@postgres:5432/jobmatching
      - REDIS_URL=redis://redis:6379
    depends_on:
      - postgres
      - redis

volumes:
  postgres_data:
```

---

## ğŸ“ˆ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æœ€é©åŒ–

### 1. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æœ€é©åŒ–
```sql
-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½œæˆ
CREATE INDEX idx_jobs_status_score ON jobs(status, combined_score DESC);
CREATE INDEX idx_jobs_location_gin ON jobs USING gin(to_tsvector('japanese', location));
CREATE INDEX idx_user_behavior_user_action ON user_behavior_logs(user_id, action_type, timestamp);

-- ãƒ‘ãƒ¼ãƒ†ã‚£ã‚·ãƒ§ãƒ‹ãƒ³ã‚°ï¼ˆå¤§è¦æ¨¡ãƒ‡ãƒ¼ã‚¿ç”¨ï¼‰
CREATE TABLE user_behavior_logs_2025_09 PARTITION OF user_behavior_logs
FOR VALUES FROM ('2025-09-01') TO ('2025-10-01');
```

### 2. ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥
```python
import redis
from functools import wraps

redis_client = redis.Redis.from_url(settings.redis_url)

def cache_result(expiry: int = 3600):
    def decorator(func):
        @wraps(func)
        async def wrapper(*args, **kwargs):
            # ã‚­ãƒ¼ç”Ÿæˆ
            cache_key = f"{func.__name__}:{hash(str(args) + str(kwargs))}"

            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç¢ºèª
            cached = redis_client.get(cache_key)
            if cached:
                return json.loads(cached)

            # å®Ÿè¡Œã—ã¦ã‚­ãƒ£ãƒƒã‚·ãƒ¥
            result = await func(*args, **kwargs)
            redis_client.setex(cache_key, expiry, json.dumps(result, default=str))

            return result
        return wrapper
    return decorator

# ä½¿ç”¨ä¾‹
@cache_result(expiry=1800)  # 30åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
async def get_user_recommendations(user_id: int):
    # æ¨è–¦å‡¦ç†
    pass
```

### 3. éåŒæœŸå‡¦ç†
```python
import asyncio
from typing import List

async def batch_process_users(user_ids: List[int], batch_size: int = 100):
    """ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®ä¸¦åˆ—å‡¦ç†"""
    semaphore = asyncio.Semaphore(8)  # æœ€å¤§8ä¸¦åˆ—

    async def process_user(user_id: int):
        async with semaphore:
            return await generate_user_recommendations(user_id)

    # ãƒãƒƒãƒã”ã¨ã«å‡¦ç†
    results = []
    for i in range(0, len(user_ids), batch_size):
        batch = user_ids[i:i + batch_size]
        batch_results = await asyncio.gather(
            *[process_user(user_id) for user_id in batch],
            return_exceptions=True
        )
        results.extend(batch_results)

    return results
```

---

ã“ã®ã‚¬ã‚¤ãƒ‰ã«ã‚ˆã‚Šã€OpenAPI 3.0ä»•æ§˜æ›¸ã‚’åŸºã«ã—ãŸFastAPIã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã®å®Ÿè£…ãŒå¯èƒ½ã«ãªã‚Šã¾ã™ã€‚ã‚¹ã‚±ãƒ¼ãƒ©ãƒ–ãƒ«ã§ä¿å®ˆæ€§ã®é«˜ã„ã‚·ã‚¹ãƒ†ãƒ æ§‹ç¯‰ã‚’æ”¯æ´ã™ã‚‹åŒ…æ‹¬çš„ãªå®Ÿè£…ä¾‹ã‚’æä¾›ã—ã¦ã„ã¾ã™ã€‚