#!/usr/bin/env python3
"""
T021: å“è³ªä¿è¨¼ãƒ†ã‚¹ãƒˆ - åŸºç¤ã‚¹ã‚³ã‚¢è¨ˆç®—
æ­£ç¢ºæ€§ã¨ä¸€è²«æ€§ã‚’æ¤œè¨¼
"""

import asyncio
import numpy as np
from typing import List, Tuple
import sys
import os
sys.path.insert(0, os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__)))))

from app.services.basic_scoring_optimized import OptimizedBasicScoringService, BatchScoringResult


class QualityTestJob:
    """å“è³ªãƒ†ã‚¹ãƒˆç”¨ã‚¸ãƒ§ãƒ–ã‚¯ãƒ©ã‚¹"""
    def __init__(self, job_id: str, fee: int, hourly_wage: int, application_clicks: int):
        self.job_id = job_id
        self.fee = fee
        self.hourly_wage = hourly_wage
        self.application_clicks = application_clicks


def validate_score_range(score: float) -> bool:
    """ã‚¹ã‚³ã‚¢ãŒæœ‰åŠ¹ç¯„å›²å†…ã‹ç¢ºèª"""
    return 0.0 <= score <= 100.0


def validate_consistency(results: List[BatchScoringResult]) -> Tuple[bool, str]:
    """çµæœã®ä¸€è²«æ€§ã‚’æ¤œè¨¼"""
    errors = []

    for result in results:
        # å„ã‚¹ã‚³ã‚¢ã®ç¯„å›²ãƒã‚§ãƒƒã‚¯
        if not validate_score_range(result.fee_score):
            errors.append(f"{result.job_id}: fee_score out of range: {result.fee_score}")
        if not validate_score_range(result.wage_score):
            errors.append(f"{result.job_id}: wage_score out of range: {result.wage_score}")
        if not validate_score_range(result.popularity_score):
            errors.append(f"{result.job_id}: popularity_score out of range: {result.popularity_score}")
        if not validate_score_range(result.combined_score):
            errors.append(f"{result.job_id}: combined_score out of range: {result.combined_score}")

        # é‡ã¿ä»˜ã‘è¨ˆç®—ã®æ¤œè¨¼
        expected_combined = (
            result.wage_score * 0.4 +
            result.fee_score * 0.3 +
            result.popularity_score * 0.3
        )
        if abs(result.combined_score - expected_combined) > 0.01:
            errors.append(
                f"{result.job_id}: combined score mismatch: "
                f"expected {expected_combined:.2f}, got {result.combined_score:.2f}"
            )

    return len(errors) == 0, "\n".join(errors)


async def test_edge_cases():
    """ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆ"""
    print("ğŸ“‹ ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)

    service = OptimizedBasicScoringService()

    # ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ã®ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    edge_cases = [
        # (job_id, fee, hourly_wage, clicks, description)
        ("ZERO_VALUES", 0, 0, 0, "å…¨ã‚¼ãƒ­å€¤"),
        ("MIN_THRESHOLD", 500, 1000, 0, "é–¾å€¤å¢ƒç•Œ"),
        ("JUST_ABOVE", 501, 1001, 1, "é–¾å€¤ç›´ä¸Š"),
        ("MAX_VALUES", 10000, 5000, 10000, "æœ€å¤§å€¤"),
        ("NEGATIVE_FEE", -100, 1500, 100, "è² ã®fee"),
        ("HUGE_VALUES", 999999, 999999, 999999, "å·¨å¤§å€¤"),
    ]

    jobs = [QualityTestJob(ec[0], ec[1], ec[2], ec[3]) for ec in edge_cases]
    results = await service.batch_calculate_scores(jobs)

    print("çµæœ:")
    for i, result in enumerate(results):
        desc = edge_cases[i][4]
        print(f"  {result.job_id} ({desc}):")
        print(f"    Fee: {result.fee_score:.1f}, Wage: {result.wage_score:.1f}, "
              f"Pop: {result.popularity_score:.1f}, Combined: {result.combined_score:.1f}")

        # è² ã®å€¤ãƒã‚§ãƒƒã‚¯
        assert result.fee_score >= 0, f"Negative fee score: {result.fee_score}"
        assert result.wage_score >= 0, f"Negative wage score: {result.wage_score}"
        assert result.popularity_score >= 0, f"Negative popularity score: {result.popularity_score}"
        assert result.combined_score >= 0, f"Negative combined score: {result.combined_score}"

    print("âœ… ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹ãƒ†ã‚¹ãƒˆåˆæ ¼")
    return True


async def test_statistical_distribution():
    """çµ±è¨ˆçš„åˆ†å¸ƒã®ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ“Š çµ±è¨ˆçš„åˆ†å¸ƒãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)

    service = OptimizedBasicScoringService()

    # æ­£è¦åˆ†å¸ƒã«å¾“ã†ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ç”Ÿæˆ
    np.random.seed(42)
    n_samples = 10000

    # ç¾å®Ÿçš„ãªåˆ†å¸ƒã®ã‚·ãƒŸãƒ¥ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
    fees = np.random.gamma(2, 1000, n_samples).clip(0, 10000)
    wages = np.random.normal(1500, 500, n_samples).clip(800, 3000)
    clicks = np.random.poisson(100, n_samples)

    jobs = [
        QualityTestJob(f"STAT_{i:05d}", int(fees[i]), int(wages[i]), int(clicks[i]))
        for i in range(n_samples)
    ]

    # ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
    results = await service.batch_calculate_scores(jobs)

    # çµ±è¨ˆæƒ…å ±åé›†
    combined_scores = [r.combined_score for r in results]
    mean_score = np.mean(combined_scores)
    std_score = np.std(combined_scores)
    min_score = np.min(combined_scores)
    max_score = np.max(combined_scores)

    print(f"ç·åˆã‚¹ã‚³ã‚¢çµ±è¨ˆ:")
    print(f"  å¹³å‡: {mean_score:.2f}")
    print(f"  æ¨™æº–åå·®: {std_score:.2f}")
    print(f"  æœ€å°å€¤: {min_score:.2f}")
    print(f"  æœ€å¤§å€¤: {max_score:.2f}")

    # åˆ†å¸ƒã®å¦¥å½“æ€§ãƒã‚§ãƒƒã‚¯
    assert 20 <= mean_score <= 80, f"Mean score out of expected range: {mean_score}"
    assert 5 <= std_score <= 30, f"Std deviation out of expected range: {std_score}"
    assert min_score >= 0, f"Minimum score negative: {min_score}"
    assert max_score <= 100, f"Maximum score exceeds 100: {max_score}"

    # ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«åˆ†æ
    percentiles = [0, 25, 50, 75, 100]
    pct_values = np.percentile(combined_scores, percentiles)
    print(f"\nãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«:")
    for p, v in zip(percentiles, pct_values):
        print(f"  {p}%: {v:.2f}")

    print("âœ… çµ±è¨ˆçš„åˆ†å¸ƒãƒ†ã‚¹ãƒˆåˆæ ¼")
    return True


async def test_deterministic_behavior():
    """æ±ºå®šè«–çš„å‹•ä½œã®ãƒ†ã‚¹ãƒˆï¼ˆåŒã˜å…¥åŠ›â†’åŒã˜å‡ºåŠ›ï¼‰"""
    print("\nğŸ”’ æ±ºå®šè«–çš„å‹•ä½œãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)

    service = OptimizedBasicScoringService()

    # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿
    test_jobs = [
        QualityTestJob("DET_001", 1000, 1500, 100),
        QualityTestJob("DET_002", 2000, 2000, 200),
        QualityTestJob("DET_003", 3000, 2500, 150),
    ]

    # 10å›å®Ÿè¡Œã—ã¦çµæœãŒåŒã˜ã‹ç¢ºèª
    all_results = []
    for run in range(10):
        results = await service.batch_calculate_scores(test_jobs)
        all_results.append(results)

    # çµæœã®ä¸€è²«æ€§ç¢ºèª
    for i in range(1, 10):
        for j, job in enumerate(test_jobs):
            r1 = all_results[0][j]
            r2 = all_results[i][j]

            assert r1.fee_score == r2.fee_score, f"Fee score mismatch in run {i}"
            assert r1.wage_score == r2.wage_score, f"Wage score mismatch in run {i}"
            assert r1.popularity_score == r2.popularity_score, f"Popularity score mismatch in run {i}"
            assert r1.combined_score == r2.combined_score, f"Combined score mismatch in run {i}"

    print(f"âœ… 10å›å®Ÿè¡Œã§å®Œå…¨ä¸€è‡´ã‚’ç¢ºèª")
    return True


async def test_boundary_conditions():
    """å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ"""
    print("\nğŸ” å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆ:")
    print("-" * 40)

    service = OptimizedBasicScoringService()

    # å¢ƒç•Œå€¤ã®ãƒ†ã‚¹ãƒˆã‚±ãƒ¼ã‚¹
    boundary_cases = [
        # feeå¢ƒç•Œï¼ˆ500ãŒé–¾å€¤ï¼‰
        (499, 1500, 100, "Feeå¢ƒç•Œä¸‹"),
        (500, 1500, 100, "Feeå¢ƒç•Œ"),
        (501, 1500, 100, "Feeå¢ƒç•Œä¸Š"),
        # wageå¢ƒç•Œï¼ˆ1000ãŒé–¾å€¤ï¼‰
        (1000, 999, 100, "Wageå¢ƒç•Œä¸‹"),
        (1000, 1000, 100, "Wageå¢ƒç•Œ"),
        (1000, 1001, 100, "Wageå¢ƒç•Œä¸Š"),
        # æœ€å¤§å€¤ãƒ†ã‚¹ãƒˆ
        (5000, 3000, 1000, "Fee/Wageæœ€å¤§å€¤"),
        (10000, 5000, 2000, "è¶…æœ€å¤§å€¤"),
    ]

    for fee, wage, clicks, desc in boundary_cases:
        job = QualityTestJob(f"BOUNDARY_{desc}", fee, wage, clicks)
        results = await service.batch_calculate_scores([job])
        result = results[0]

        print(f"{desc}:")
        print(f"  å…¥åŠ›: fee={fee}, wage={wage}, clicks={clicks}")
        print(f"  å‡ºåŠ›: fee_score={result.fee_score:.1f}, "
              f"wage_score={result.wage_score:.1f}, "
              f"combined={result.combined_score:.1f}")

        # å¢ƒç•Œå€¤ã§ã®æ­£ã—ã„å‹•ä½œç¢ºèª
        if fee <= 500:
            assert result.fee_score == 0.0, f"Fee score should be 0 for fee={fee}"
        if wage <= 1000:
            assert result.wage_score == 0.0, f"Wage score should be 0 for wage={wage}"

    print("âœ… å¢ƒç•Œå€¤ãƒ†ã‚¹ãƒˆåˆæ ¼")
    return True


async def run_quality_tests():
    """å…¨å“è³ªãƒ†ã‚¹ãƒˆå®Ÿè¡Œ"""
    print("=" * 60)
    print("T021: åŸºç¤ã‚¹ã‚³ã‚¢è¨ˆç®— - å“è³ªä¿è¨¼ãƒ†ã‚¹ãƒˆ")
    print("=" * 60)

    tests = [
        ("ã‚¨ãƒƒã‚¸ã‚±ãƒ¼ã‚¹", test_edge_cases),
        ("çµ±è¨ˆçš„åˆ†å¸ƒ", test_statistical_distribution),
        ("æ±ºå®šè«–çš„å‹•ä½œ", test_deterministic_behavior),
        ("å¢ƒç•Œå€¤æ¡ä»¶", test_boundary_conditions),
    ]

    passed = 0
    failed = 0

    for name, test_func in tests:
        try:
            result = await test_func()
            if result:
                passed += 1
        except Exception as e:
            print(f"âŒ {name}ãƒ†ã‚¹ãƒˆå¤±æ•—: {e}")
            failed += 1

    print("\n" + "=" * 60)
    print(f"ğŸ“Š ãƒ†ã‚¹ãƒˆçµæœ: {passed}/{len(tests)} åˆæ ¼")

    if failed == 0:
        print("ğŸ‰ å…¨å“è³ªãƒ†ã‚¹ãƒˆåˆæ ¼ï¼")
        return True
    else:
        print(f"âš ï¸ {failed}å€‹ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
        return False


if __name__ == "__main__":
    result = asyncio.run(run_quality_tests())
    sys.exit(0 if result else 1)