"""
T067: Supabaseã‚¹ã‚­ãƒ¼ãƒžç§»è¡Œ - TDD RED Phase
å¤±æ•—ã™ã‚‹ãƒ†ã‚¹ãƒˆã‚’ä½œæˆï¼ˆ20ãƒ†ãƒ¼ãƒ–ãƒ«ã‚¹ã‚­ãƒ¼ãƒžç¢ºèªï¼‰
"""

import pytest
import asyncio
import asyncpg
from typing import List, Dict


class TestSupabaseSchema:
    """Supabaseã‚¹ã‚­ãƒ¼ãƒžç§»è¡Œãƒ†ã‚¹ãƒˆ - RED Phaseï¼ˆå¿…ãšå¤±æ•—ã™ã‚‹ï¼‰"""

    @pytest.fixture
    async def db_connection(self):
        """Supabase PostgreSQLæŽ¥ç¶š"""
        conn = await asyncpg.connect(
            host="localhost",
            port=54322,
            database="postgres",
            user="postgres",
            password="postgres"
        )
        yield conn
        await conn.close()

    @pytest.mark.asyncio
    async def test_job_matching_tables_count(self, db_connection):
        """
        ãƒ†ã‚¹ãƒˆ: ã‚¸ãƒ§ãƒ–ãƒžãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ ç”¨ãƒ†ãƒ¼ãƒ–ãƒ«æ•°ç¢ºèª
        æœŸå¾…çµæžœ: ç¾åœ¨ã¯å¤±æ•—ï¼ˆ20ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå­˜åœ¨ã—ãªã„ï¼‰
        """
        # æœŸå¾…ã•ã‚Œã‚‹20ãƒ†ãƒ¼ãƒ–ãƒ«
        expected_tables = [
            # ãƒžã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ (5 tables)
            'prefecture_master',
            'city_master',
            'occupation_master',
            'employment_type_master',
            'feature_master',

            # ã‚³ã‚¢ãƒ‡ãƒ¼ã‚¿ (3 tables)
            'job_data',
            'user_actions',
            'matching_results',

            # ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚° (4 tables)
            'basic_scoring',
            'seo_scoring',
            'personalized_scoring',
            'keyword_scoring',

            # ãƒãƒƒãƒå‡¦ç† (2 tables)
            'batch_jobs',
            'processing_logs',

            # ã‚»ã‚¯ã‚·ãƒ§ãƒ³ãƒ»ãƒ¡ãƒ¼ãƒ« (3 tables)
            'email_sections',
            'section_jobs',
            'email_generation_logs',

            # çµ±è¨ˆãƒ»ç›£è¦– (3 tables)
            'user_statistics',
            'semrush_keywords',
            'system_metrics'
        ]

        # å®Ÿéš›ã®ãƒ†ãƒ¼ãƒ–ãƒ«ä¸€è¦§ã‚’å–å¾—
        actual_tables = await db_connection.fetch("""
            SELECT table_name
            FROM information_schema.tables
            WHERE table_schema = 'public'
            AND table_type = 'BASE TABLE'
            ORDER BY table_name
        """)

        actual_table_names = [row['table_name'] for row in actual_tables]

        # ãƒ‡ãƒãƒƒã‚°å‡ºåŠ›
        print(f"Expected {len(expected_tables)} tables: {expected_tables}")
        print(f"Actual {len(actual_table_names)} tables: {actual_table_names}")

        # 20ãƒ†ãƒ¼ãƒ–ãƒ«ã®å­˜åœ¨ç¢ºèª
        missing_tables = [table for table in expected_tables if table not in actual_table_names]

        if missing_tables:
            pytest.fail(
                f"ðŸ”´ EXPECTED FAILURE: Missing {len(missing_tables)} tables: {missing_tables}"
            )

        # æœŸå¾…ã•ã‚Œã‚‹20ãƒ†ãƒ¼ãƒ–ãƒ«ãŒå…¨ã¦å­˜åœ¨ã™ã‚‹å ´åˆ
        assert len(actual_table_names) >= 20, f"Expected at least 20 tables, got {len(actual_table_names)}"

    @pytest.mark.asyncio
    async def test_master_data_tables_structure(self, db_connection):
        """
        ãƒ†ã‚¹ãƒˆ: ãƒžã‚¹ã‚¿ãƒ¼ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
        æœŸå¾…çµæžœ: ç¾åœ¨ã¯å¤±æ•—ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ãŒæœªå®šç¾©ï¼‰
        """
        # prefecture_master ãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
        columns = await db_connection.fetch("""
            SELECT column_name, data_type, is_nullable
            FROM information_schema.columns
            WHERE table_name = 'prefecture_master'
            AND table_schema = 'public'
            ORDER BY ordinal_position
        """)

        if not columns:
            pytest.fail("ðŸ”´ EXPECTED FAILURE: prefecture_master table does not exist")

        # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
        expected_columns = {'code', 'name', 'region', 'created_at', 'updated_at'}
        actual_columns = {row['column_name'] for row in columns}

        missing_columns = expected_columns - actual_columns
        if missing_columns:
            pytest.fail(f"ðŸ”´ Missing columns in prefecture_master: {missing_columns}")

    @pytest.mark.asyncio
    async def test_job_data_table_structure(self, db_connection):
        """
        ãƒ†ã‚¹ãƒˆ: job_dataãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ç¢ºèª
        æœŸå¾…çµæžœ: ç¾åœ¨ã¯å¤±æ•—ï¼ˆãƒ¡ã‚¤ãƒ³ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªå®šç¾©ï¼‰
        """
        columns = await db_connection.fetch("""
            SELECT column_name, data_type
            FROM information_schema.columns
            WHERE table_name = 'job_data'
            AND table_schema = 'public'
        """)

        if not columns:
            pytest.fail("ðŸ”´ EXPECTED FAILURE: job_data table does not exist")

        # é‡è¦ã‚«ãƒ©ãƒ ã®ç¢ºèª
        column_names = {row['column_name'] for row in columns}
        critical_columns = {
            'job_id', 'endcl_cd', 'fee', 'hourly_wage',
            'application_name', 'employment_type_code',
            'prefecture_cd', 'city_cd', 'occupation_code'
        }

        missing_critical = critical_columns - column_names
        if missing_critical:
            pytest.fail(f"ðŸ”´ Missing critical columns in job_data: {missing_critical}")

    @pytest.mark.asyncio
    async def test_scoring_tables_exist(self, db_connection):
        """
        ãƒ†ã‚¹ãƒˆ: ã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨ç¢ºèª
        æœŸå¾…çµæžœ: ç¾åœ¨ã¯å¤±æ•—ï¼ˆã‚¹ã‚³ã‚¢ãƒªãƒ³ã‚°ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæœªä½œæˆï¼‰
        """
        scoring_tables = [
            'basic_scoring',
            'seo_scoring',
            'personalized_scoring',
            'keyword_scoring'
        ]

        for table_name in scoring_tables:
            table_exists = await db_connection.fetchval("""
                SELECT EXISTS(
                    SELECT 1 FROM information_schema.tables
                    WHERE table_name = $1 AND table_schema = 'public'
                )
            """, table_name)

            if not table_exists:
                pytest.fail(f"ðŸ”´ EXPECTED FAILURE: {table_name} table does not exist")

    @pytest.mark.asyncio
    async def test_foreign_key_constraints(self, db_connection):
        """
        ãƒ†ã‚¹ãƒˆ: å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã®ç¢ºèª
        æœŸå¾…çµæžœ: ç¾åœ¨ã¯å¤±æ•—ï¼ˆåˆ¶ç´„ãŒæœªè¨­å®šï¼‰
        """
        # é‡è¦ãªå¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„ã‚’ç¢ºèª
        constraints = await db_connection.fetch("""
            SELECT
                tc.table_name,
                tc.constraint_name,
                kcu.column_name,
                ccu.table_name AS foreign_table_name,
                ccu.column_name AS foreign_column_name
            FROM information_schema.table_constraints tc
            JOIN information_schema.key_column_usage kcu
                ON tc.constraint_name = kcu.constraint_name
            JOIN information_schema.constraint_column_usage ccu
                ON ccu.constraint_name = tc.constraint_name
            WHERE tc.constraint_type = 'FOREIGN KEY'
            AND tc.table_schema = 'public'
        """)

        if len(constraints) == 0:
            pytest.fail("ðŸ”´ EXPECTED FAILURE: No foreign key constraints found")

        # æœ€ä½Žé™ã®å¤–éƒ¨ã‚­ãƒ¼åˆ¶ç´„æ•°ã‚’ç¢ºèª
        assert len(constraints) >= 10, f"Expected at least 10 FK constraints, got {len(constraints)}"

    @pytest.mark.asyncio
    async def test_indexes_exist(self, db_connection):
        """
        ãƒ†ã‚¹ãƒˆ: é‡è¦ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã®å­˜åœ¨ç¢ºèª
        æœŸå¾…çµæžœ: ç¾åœ¨ã¯å¤±æ•—ï¼ˆã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ãŒæœªä½œæˆï¼‰
        """
        indexes = await db_connection.fetch("""
            SELECT indexname, tablename, indexdef
            FROM pg_indexes
            WHERE schemaname = 'public'
            AND indexname NOT LIKE '%_pkey'
        """)

        if len(indexes) == 0:
            pytest.fail("ðŸ”´ EXPECTED FAILURE: No custom indexes found")

        # æœ€ä½Žé™ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ•°ã‚’ç¢ºèªï¼ˆä¸»ã‚­ãƒ¼ä»¥å¤–ï¼‰
        assert len(indexes) >= 15, f"Expected at least 15 custom indexes, got {len(indexes)}"


if __name__ == "__main__":
    pytest.main([__file__, "-v", "--tb=short"])