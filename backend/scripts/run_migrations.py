#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¹ã‚¯ãƒªãƒ—ãƒˆ
SQLiteã¨PostgreSQLä¸¡å¯¾å¿œ
"""

import os
import sys
import sqlite3
import asyncio
import argparse
from pathlib import Path
from typing import List, Dict, Any
from datetime import datetime

# ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹ã‚’è¿½åŠ 
sys.path.insert(0, str(Path(__file__).parent.parent))

from app.core.config import settings
from app.core.database import engine, get_db


class MigrationRunner:
    """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        self.backend_dir = Path(__file__).parent.parent
        self.migrations_dir = self.backend_dir / "migrations"
        self.db_url = settings.DATABASE_URL
        self.is_sqlite = "sqlite" in self.db_url

    def get_migration_files(self) -> List[Path]:
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—"""
        sql_files = sorted(self.migrations_dir.glob("*.sql"))
        return sql_files

    def run_sqlite_migrations(self) -> None:
        """SQLiteç”¨ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        print("ğŸ—„ï¸ SQLite migrations starting...")

        # SQLiteãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ‘ã‚¹ã‚’å–å¾—
        db_path = self.db_url.replace("sqlite+aiosqlite:///", "").replace("sqlite:///", "")
        if db_path.startswith("./"):
            db_path = self.backend_dir / db_path[2:]

        # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS migration_history (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                filename TEXT UNIQUE NOT NULL,
                applied_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        """)

        # æ—¢ã«é©ç”¨æ¸ˆã¿ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—
        cursor.execute("SELECT filename FROM migration_history")
        applied = {row[0] for row in cursor.fetchall()}

        # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡å®Ÿè¡Œ
        migration_files = self.get_migration_files()

        for migration_file in migration_files:
            filename = migration_file.name

            # ã‚¹ã‚­ãƒƒãƒ—æ¡ä»¶
            if filename in applied:
                print(f"â­ï¸  Skipping {filename} (already applied)")
                continue

            if "supabase" in filename.lower() or "rls" in filename.lower():
                print(f"â­ï¸  Skipping {filename} (Supabase-specific)")
                continue

            print(f"ğŸ“ Applying {filename}...")

            # SQLã‚’èª­ã¿è¾¼ã¿ã€SQLiteç”¨ã«å¤‰æ›
            with open(migration_file, "r", encoding="utf-8") as f:
                sql = f.read()

            # SQLiteç”¨ã«å¤‰æ›
            sql = self.convert_to_sqlite(sql)

            # å®Ÿè¡Œ
            try:
                # è¤‡æ•°ã®ã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’å®Ÿè¡Œ
                cursor.executescript(sql)

                # å±¥æ­´ã«è¨˜éŒ²
                cursor.execute(
                    "INSERT INTO migration_history (filename) VALUES (?)",
                    (filename,)
                )
                conn.commit()
                print(f"âœ… {filename} applied successfully")

            except Exception as e:
                print(f"âŒ Error applying {filename}: {e}")
                conn.rollback()
                raise

        conn.close()
        print("âœ… SQLite migrations completed")

    def convert_to_sqlite(self, sql: str) -> str:
        """PostgreSQL SQLã‚’SQLiteç”¨ã«å¤‰æ›"""
        # ã‚³ãƒ¡ãƒ³ãƒˆã‚’é™¤å»
        lines = sql.split('\n')
        cleaned_lines = []

        for line in lines:
            # COMMENTã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã‚’ã‚¹ã‚­ãƒƒãƒ—
            if line.strip().upper().startswith('COMMENT ON'):
                continue

            # CREATE INDEXã‚¹ãƒ†ãƒ¼ãƒˆãƒ¡ãƒ³ãƒˆã¯ã‚¹ã‚­ãƒƒãƒ—ï¼ˆå¾Œã§åˆ¥é€”å‡¦ç†ï¼‰
            if 'CREATE INDEX' in line.upper():
                continue

            # å‹å¤‰æ›
            line = line.replace('SERIAL PRIMARY KEY', 'INTEGER PRIMARY KEY AUTOINCREMENT')
            line = line.replace('BIGSERIAL PRIMARY KEY', 'INTEGER PRIMARY KEY AUTOINCREMENT')
            line = line.replace('SERIAL', 'INTEGER')
            line = line.replace('BIGSERIAL', 'INTEGER')
            line = line.replace('VARCHAR', 'TEXT')
            line = line.replace('CHAR(2)', 'TEXT')
            line = line.replace('CHAR(5)', 'TEXT')
            line = line.replace('TIMESTAMPTZ', 'TIMESTAMP')
            line = line.replace('TIMESTAMP WITH TIME ZONE', 'TIMESTAMP')
            line = line.replace('JSONB', 'TEXT')
            line = line.replace('JSON', 'TEXT')
            line = line.replace('UUID', 'TEXT')
            line = line.replace('DECIMAL', 'REAL')
            line = line.replace('NUMERIC', 'REAL')
            line = line.replace('BYTEA', 'BLOB')
            line = line.replace('[]', '')  # é…åˆ—å‹ã‚’å‰Šé™¤

            # å¤–éƒ¨ã‚­ãƒ¼å‚ç…§ã‚’ç°¡ç•¥åŒ–ï¼ˆSQLiteã§ã¯åˆ¶ç´„åã¯ã‚ªãƒ—ã‚·ãƒ§ãƒ³ï¼‰
            if 'REFERENCES' in line:
                line = line.replace('NOT NULL REFERENCES', 'REFERENCES')

            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®å¤‰æ›
            line = line.replace('DEFAULT CURRENT_TIMESTAMP', "DEFAULT (datetime('now'))")
            line = line.replace('DEFAULT NOW()', "DEFAULT (datetime('now'))")
            line = line.replace('DEFAULT gen_random_uuid()', "")

            # IF NOT EXISTS ã‚’ã‚µãƒãƒ¼ãƒˆ
            # SQLiteã¯3.3.0ä»¥é™ã§ã‚µãƒãƒ¼ãƒˆ

            cleaned_lines.append(line)

        return '\n'.join(cleaned_lines)

    async def run_postgresql_migrations(self) -> None:
        """PostgreSQL/Supabaseç”¨ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        print("ğŸ˜ PostgreSQL/Supabase migrations starting...")

        async with engine.begin() as conn:
            # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å±¥æ­´ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
            await conn.execute("""
                CREATE TABLE IF NOT EXISTS migration_history (
                    id SERIAL PRIMARY KEY,
                    filename TEXT UNIQUE NOT NULL,
                    applied_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
                )
            """)

            # æ—¢ã«é©ç”¨æ¸ˆã¿ã®ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å–å¾—
            result = await conn.execute("SELECT filename FROM migration_history")
            applied = {row[0] for row in result}

            # ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é †æ¬¡å®Ÿè¡Œ
            migration_files = self.get_migration_files()

            for migration_file in migration_files:
                filename = migration_file.name

                if filename in applied:
                    print(f"â­ï¸  Skipping {filename} (already applied)")
                    continue

                print(f"ğŸ“ Applying {filename}...")

                # SQLã‚’èª­ã¿è¾¼ã¿
                with open(migration_file, "r", encoding="utf-8") as f:
                    sql = f.read()

                try:
                    # å®Ÿè¡Œ
                    await conn.execute(sql)

                    # å±¥æ­´ã«è¨˜éŒ²
                    await conn.execute(
                        "INSERT INTO migration_history (filename) VALUES (:filename)",
                        {"filename": filename}
                    )

                    print(f"âœ… {filename} applied successfully")

                except Exception as e:
                    print(f"âŒ Error applying {filename}: {e}")
                    raise

        print("âœ… PostgreSQL migrations completed")

    def run(self) -> None:
        """ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ"""
        print(f"ğŸš€ Starting database migrations")
        print(f"ğŸ“ Database: {self.db_url[:50]}...")
        print(f"ğŸ“‚ Migrations directory: {self.migrations_dir}")

        if self.is_sqlite:
            self.run_sqlite_migrations()
        else:
            asyncio.run(self.run_postgresql_migrations())

        print("âœ¨ All migrations completed successfully!")

    def create_test_tables(self) -> None:
        """ãƒ†ã‚¹ãƒˆç”¨ã®ç°¡æ˜“ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆï¼ˆé–‹ç™ºç”¨ï¼‰"""
        if not self.is_sqlite:
            print("âš ï¸  Test tables are only for SQLite development")
            return

        print("ğŸ§ª Creating test tables for development...")

        db_path = self.db_url.replace("sqlite+aiosqlite:///", "").replace("sqlite:///", "")
        if db_path.startswith("./"):
            db_path = self.backend_dir / db_path[2:]

        conn = sqlite3.connect(db_path)
        cursor = conn.cursor()

        # æœ€å°é™ã®ãƒ†ã‚¹ãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
        cursor.execute("""
            CREATE TABLE IF NOT EXISTS jobs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                title TEXT NOT NULL,
                company TEXT NOT NULL,
                salary INTEGER,
                created_at TIMESTAMP DEFAULT (datetime('now'))
            )
        """)

        cursor.execute("""
            CREATE TABLE IF NOT EXISTS users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                email TEXT UNIQUE NOT NULL,
                name TEXT,
                created_at TIMESTAMP DEFAULT (datetime('now'))
            )
        """)

        # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿æŒ¿å…¥ï¼ˆãƒ†ãƒ¼ãƒ–ãƒ«å­˜åœ¨æ™‚ã®ã¿ï¼‰
        try:
            cursor.execute("""
                INSERT OR IGNORE INTO jobs (title, company, salary)
                VALUES
                    ('Backend Developer', 'Tech Corp', 500000),
                    ('Frontend Developer', 'Web Inc', 450000),
                    ('Full Stack Developer', 'Startup Co', 480000)
            """)
        except sqlite3.OperationalError as e:
            print(f"âš ï¸  Could not insert sample data: {e}")

        cursor.execute("""
            INSERT OR IGNORE INTO users (email, name)
            VALUES
                ('test@example.com', 'Test User'),
                ('admin@example.com', 'Admin User')
        """)

        conn.commit()
        conn.close()

        print("âœ… Test tables created successfully")


def main():
    parser = argparse.ArgumentParser(description="Run database migrations")
    parser.add_argument(
        "--test-tables",
        action="store_true",
        help="Create test tables for development"
    )
    parser.add_argument(
        "--force",
        action="store_true",
        help="Force re-run all migrations (dangerous!)"
    )

    args = parser.parse_args()

    runner = MigrationRunner()

    if args.test_tables:
        runner.create_test_tables()
    else:
        runner.run()


if __name__ == "__main__":
    main()