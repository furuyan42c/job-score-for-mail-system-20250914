# Diffãƒã‚§ãƒƒã‚¯ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ ã‚®ãƒ£ãƒƒãƒ—åˆ†æ
åˆ†ææ—¥æ™‚: 2025-08-25 15:30:00

## ğŸ” **ç¾åœ¨å®Ÿè£…ã®è©³ç´°èª¿æŸ»çµæœ**

### **Diffãƒã‚§ãƒƒã‚¯ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ã®å®Ÿè£…çŠ¶æ³**
```yaml
Current_Diff_Review_Status:
  pre_commit_diff_analysis: "âŒ æœªå®Ÿè£…"
  code_quality_review: "âŒ æœªå®Ÿè£…"
  automated_code_review: "âŒ æœªå®Ÿè£…"
  change_impact_analysis: "âŒ æœªå®Ÿè£…"
  diff_safety_validation: "âŒ åŸºæœ¬çš„ãªå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯ã®ã¿"

  existing_validation_features:
    basic_commit_safety: "âœ… validate_commit_safety()å®Ÿè£…æ¸ˆã¿"
    file_syntax_validation: "âœ… ä¸€éƒ¨å®Ÿè£…æ¸ˆã¿"
    conflict_detection: "âœ… æ–°è¦å®Ÿè£…æ¸ˆã¿"
```

### **ç™ºè¦‹ã•ã‚ŒãŸé‡å¤§ãªã‚®ãƒ£ãƒƒãƒ—**
```yaml
Critical_Diff_Review_Gaps:
  no_pre_commit_diff_review:
    problem: "ã‚³ãƒŸãƒƒãƒˆå‰ã®diffå†…å®¹åˆ†æãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãªã—"
    risk: "å•é¡Œã®ã‚ã‚‹ã‚³ãƒ¼ãƒ‰å¤‰æ›´ã®è¦‹è½ã¨ã—ãƒ»å“è³ªä½ä¸‹"
    impact_level: "HIGH"

  no_automated_code_review:
    problem: "è‡ªå‹•åŒ–ã•ã‚ŒãŸã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãªã—"
    risk: "ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„é•åãƒ»æ½œåœ¨çš„ãƒã‚°ã®è¦‹è½ã¨ã—"
    impact_level: "HIGH"

  no_change_impact_analysis:
    problem: "å¤‰æ›´ã®å½±éŸ¿ç¯„å›²åˆ†ææ©Ÿèƒ½ãªã—"
    risk: "æ„å›³ã—ãªã„å‰¯ä½œç”¨ãƒ»ç ´å£Šçš„å¤‰æ›´ã®è¦‹è½ã¨ã—"
    impact_level: "HIGH"

  no_diff_visualization:
    problem: "diffå†…å®¹ã®å¯è¦–åŒ–ãƒ»äººé–“ãƒ¬ãƒ“ãƒ¥ãƒ¼æ”¯æ´æ©Ÿèƒ½ãªã—"
    risk: "è¤‡é›‘ãªå¤‰æ›´ã®ç†è§£å›°é›£ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼åŠ¹ç‡ä½ä¸‹"
    impact_level: "MEDIUM"

  no_review_approval_flow:
    problem: "ãƒ¬ãƒ“ãƒ¥ãƒ¼ãƒ»æ‰¿èªãƒ•ãƒ­ãƒ¼æ©Ÿèƒ½ãªã—"
    risk: "GitHubæ¨™æº–ãƒ¯ãƒ¼ã‚¯ãƒ•ãƒ­ãƒ¼ã‹ã‚‰ã®ä¹–é›¢"
    impact_level: "MEDIUM"
```

## ğŸš¨ **å…·ä½“çš„ãƒªã‚¹ã‚¯ã‚·ãƒŠãƒªã‚ª**

### **ã‚·ãƒŠãƒªã‚ª1: å±é™ºãªã‚³ãƒ¼ãƒ‰å¤‰æ›´ã®è¦‹è½ã¨ã—**
```yaml
Dangerous_Code_Change_Scenario:
  situation: |
    - supabase-specialist: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹èªè¨¼ã‚³ãƒ¼ãƒ‰ã‚’å¤‰æ›´
    - å¤‰æ›´ã«ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ›ãƒ¼ãƒ«å«æœ‰
    - diffãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãªã—ã§è‡ªå‹•ã‚³ãƒŸãƒƒãƒˆ

  current_behavior: |
    1. validate_commit_safety()ã§åŸºæœ¬ãƒã‚§ãƒƒã‚¯ã®ã¿
    2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®æ¤œçŸ¥ã§ããš
    3. å±é™ºãªã‚³ãƒ¼ãƒ‰ãŒæœ¬ç•ªç’°å¢ƒã«ãƒ‡ãƒ—ãƒ­ã‚¤
    4. ãƒ‡ãƒ¼ã‚¿æ¼æ´©ãƒ»ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³ç™ºç”Ÿ

  risk_assessment:
    probability: "MEDIUMï¼ˆè¤‡é›‘ãªå¤‰æ›´æ™‚ï¼‰"
    impact: "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ä¾µå®³ãƒ»é‡å¤§ãªäº‹æ•…"
    recovery_time: "ç·Šæ€¥å¯¾å¿œãƒ»æ•°æ—¥ã®ä¿®å¾©ä½œæ¥­"
```

### **ã‚·ãƒŠãƒªã‚ª2: ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åŠ£åŒ–ã®è¦‹è½ã¨ã—**
```yaml
Performance_Degradation_Scenario:
  situation: |
    - batch-performance-optimizer: SQLã‚¯ã‚¨ãƒªæœ€é©åŒ–å®Ÿè£…
    - æœ€é©åŒ–ã«ã‚ˆã‚Šåˆ¥ã®å‡¦ç†ãŒå¤§å¹…ã«é…ããªã‚‹
    - å½±éŸ¿ç¯„å›²åˆ†ææ©Ÿèƒ½ãªã—

  current_behavior: |
    1. æ§‹æ–‡ã‚¨ãƒ©ãƒ¼ãªã—ã§ã‚³ãƒŸãƒƒãƒˆé€šé
    2. å‰¯ä½œç”¨ã®å½±éŸ¿ç¯„å›²æœªåˆ†æ
    3. æœ¬ç•ªã§ãƒãƒƒãƒå‡¦ç†æ™‚é–“ãŒ10å€ã«å¢—åŠ 
    4. SLAé•åãƒ»ã‚·ã‚¹ãƒ†ãƒ åœæ­¢

  risk_assessment:
    probability: "MEDIUMï¼ˆæœ€é©åŒ–ãƒ»ãƒªãƒ•ã‚¡ã‚¯ã‚¿æ™‚ï¼‰"
    impact: "ã‚·ã‚¹ãƒ†ãƒ æ€§èƒ½åŠ£åŒ–ãƒ»SLAé•å"
    recovery_time: "åŸå› èª¿æŸ»ãƒ»ç·Šæ€¥ä¿®æ­£ã§æ•°æ™‚é–“"
```

### **ã‚·ãƒŠãƒªã‚ª3: ä¸é©åˆ‡ãªã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„é•å**
```yaml
Code_Standard_Violation_Scenario:
  situation: |
    - thorough-todo-executor: æ–°æ©Ÿèƒ½å®Ÿè£…
    - TypeScriptå‹å®šç¾©ãŒä¸é©åˆ‡ãƒ»å‘½åè¦ç´„é•å
    - è‡ªå‹•ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãªã—

  current_behavior: |
    1. åŸºæœ¬çš„ãªæ§‹æ–‡ãƒã‚§ãƒƒã‚¯ã®ã¿é€šé
    2. å‹å®‰å…¨æ€§ãƒ»ä¿å®ˆæ€§ã®å•é¡Œæœªæ¤œçŸ¥
    3. æŠ€è¡“å‚µå‹™ã®è“„ç©ãƒ»ã‚³ãƒ¼ãƒ‰å“è³ªåŠ£åŒ–
    4. å°†æ¥çš„ãªé–‹ç™ºåŠ¹ç‡ä½ä¸‹

  risk_assessment:
    probability: "HIGHï¼ˆç¶™ç¶šçš„ãªé–‹ç™ºã§é »ç™ºï¼‰"
    impact: "ã‚³ãƒ¼ãƒ‰å“è³ªåŠ£åŒ–ãƒ»é–‹ç™ºåŠ¹ç‡ä½ä¸‹"
    recovery_time: "å®šæœŸçš„ãªãƒªãƒ•ã‚¡ã‚¯ã‚¿ãƒªãƒ³ã‚°ã§æ•°æ—¥"
```

## ğŸ’» **å¿…è¦ãªæ©Ÿèƒ½å®Ÿè£…**

### **Phase 1: Pre-Commitãƒ‡ã‚£ãƒ•åˆ†æ**
```python
def perform_pre_commit_diff_analysis(commit_files):
    """ã‚³ãƒŸãƒƒãƒˆå‰ã®diffåŒ…æ‹¬åˆ†æ"""
    analysis_results = []

    for file_path in commit_files:
        # 1. ãƒ•ã‚¡ã‚¤ãƒ«å¤‰æ›´å·®åˆ†ã®å–å¾—
        diff_data = get_detailed_file_diff(file_path)

        # 2. å¤‰æ›´ã‚¿ã‚¤ãƒ—ã®åˆ†é¡
        change_classification = classify_change_type(diff_data)

        # 3. ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«è©•ä¾¡
        risk_assessment = assess_change_risk_level(diff_data, change_classification)

        # 4. è©³ç´°åˆ†æå®Ÿè¡Œ
        detailed_analysis = perform_detailed_diff_analysis(file_path, diff_data, risk_assessment)

        analysis_results.append(DiffAnalysisResult(
            file_path=file_path,
            change_type=change_classification,
            risk_level=risk_assessment.level,
            detailed_findings=detailed_analysis.findings,
            recommended_actions=detailed_analysis.recommendations,
            requires_human_review=risk_assessment.level in ['HIGH', 'CRITICAL']
        ))

    return PreCommitAnalysisResult(
        file_analyses=analysis_results,
        overall_risk_level=calculate_overall_risk(analysis_results),
        blocking_issues=extract_blocking_issues(analysis_results),
        human_review_required=any(a.requires_human_review for a in analysis_results)
    )

def classify_change_type(diff_data):
    """å¤‰æ›´ã‚¿ã‚¤ãƒ—ã®è©³ç´°åˆ†é¡"""
    change_patterns = analyze_diff_patterns(diff_data)

    if change_patterns.has_security_sensitive_changes:
        return ChangeClassification(
            primary_type='SECURITY_SENSITIVE',
            sub_types=change_patterns.security_change_types,
            confidence=change_patterns.security_confidence
        )
    elif change_patterns.has_performance_implications:
        return ChangeClassification(
            primary_type='PERFORMANCE_CRITICAL',
            sub_types=change_patterns.performance_change_types,
            confidence=change_patterns.performance_confidence
        )
    elif change_patterns.has_database_schema_changes:
        return ChangeClassification(
            primary_type='DATABASE_SCHEMA',
            sub_types=['MIGRATION', 'TABLE_STRUCTURE', 'INDEX_CHANGES'],
            confidence=0.95
        )
    elif change_patterns.has_api_interface_changes:
        return ChangeClassification(
            primary_type='API_BREAKING',
            sub_types=change_patterns.api_change_types,
            confidence=change_patterns.api_confidence
        )
    else:
        return ChangeClassification(
            primary_type='ROUTINE_CHANGE',
            sub_types=change_patterns.routine_types,
            confidence=0.8
        )

def assess_change_risk_level(diff_data, change_classification):
    """å¤‰æ›´ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«ã®è©³ç´°è©•ä¾¡"""
    base_risk = get_base_risk_for_change_type(change_classification.primary_type)

    # å¤‰æ›´è¦æ¨¡ã«ã‚ˆã‚‹èª¿æ•´
    scale_multiplier = calculate_change_scale_multiplier(diff_data)

    # å¤‰æ›´è¤‡é›‘åº¦ã«ã‚ˆã‚‹èª¿æ•´
    complexity_multiplier = calculate_change_complexity_multiplier(diff_data)

    # ãƒ•ã‚¡ã‚¤ãƒ«é‡è¦åº¦ã«ã‚ˆã‚‹èª¿æ•´
    file_importance_multiplier = get_file_importance_multiplier(diff_data.file_path)

    # æœ€çµ‚ãƒªã‚¹ã‚¯ã‚¹ã‚³ã‚¢è¨ˆç®—
    final_risk_score = base_risk * scale_multiplier * complexity_multiplier * file_importance_multiplier

    # ãƒªã‚¹ã‚¯ãƒ¬ãƒ™ãƒ«åˆ¤å®š
    if final_risk_score >= 0.8:
        risk_level = 'CRITICAL'
    elif final_risk_score >= 0.6:
        risk_level = 'HIGH'
    elif final_risk_score >= 0.4:
        risk_level = 'MEDIUM'
    else:
        risk_level = 'LOW'

    return RiskAssessmentResult(
        level=risk_level,
        score=final_risk_score,
        contributing_factors={
            'change_type': change_classification.primary_type,
            'scale': scale_multiplier,
            'complexity': complexity_multiplier,
            'file_importance': file_importance_multiplier
        },
        mitigation_suggestions=generate_risk_mitigation_suggestions(risk_level, change_classification)
    )
```

### **Phase 2: è‡ªå‹•ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼ã‚·ã‚¹ãƒ†ãƒ **
```python
def perform_automated_code_review(file_path, diff_data):
    """è‡ªå‹•åŒ–ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼å®Ÿè¡Œ"""
    review_results = []

    # 1. TypeScript/JavaScriptç‰¹åŒ–ãƒ¬ãƒ“ãƒ¥ãƒ¼
    if file_path.endswith(('.ts', '.js', '.tsx', '.jsx')):
        ts_review = perform_typescript_review(file_path, diff_data)
        review_results.extend(ts_review.findings)

    # 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
    security_review = perform_security_vulnerability_scan(file_path, diff_data)
    review_results.extend(security_review.findings)

    # 3. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿åˆ†æ
    performance_review = analyze_performance_impact(file_path, diff_data)
    review_results.extend(performance_review.findings)

    # 4. ã‚³ãƒ¼ãƒ‡ã‚£ãƒ³ã‚°è¦ç´„æº–æ‹ ãƒã‚§ãƒƒã‚¯
    style_review = check_coding_standards_compliance(file_path, diff_data)
    review_results.extend(style_review.findings)

    # 5. ãƒ†ã‚¹ãƒˆã‚«ãƒãƒ¬ãƒƒã‚¸å½±éŸ¿åˆ†æ
    test_coverage_review = analyze_test_coverage_impact(file_path, diff_data)
    review_results.extend(test_coverage_review.findings)

    return AutomatedReviewResult(
        file_path=file_path,
        findings=review_results,
        overall_score=calculate_review_score(review_results),
        critical_issues=extract_critical_issues(review_results),
        recommendations=generate_improvement_recommendations(review_results)
    )

def perform_typescript_review(file_path, diff_data):
    """TypeScriptç‰¹åŒ–ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼"""
    findings = []

    # å‹å®šç¾©ã®é©åˆ‡æ€§ãƒã‚§ãƒƒã‚¯
    type_analysis = analyze_typescript_types(diff_data.added_lines)
    if type_analysis.has_issues:
        findings.extend([
            ReviewFinding(
                type='TYPE_SAFETY',
                severity='HIGH',
                message=f"Type definition issues: {issue}",
                line_number=issue.line_number,
                suggestion=issue.suggested_fix
            ) for issue in type_analysis.issues
        ])

    # null/undefinedå®‰å…¨æ€§ãƒã‚§ãƒƒã‚¯
    nullability_analysis = check_null_safety(diff_data.added_lines)
    if nullability_analysis.has_risks:
        findings.extend([
            ReviewFinding(
                type='NULL_SAFETY',
                severity='MEDIUM',
                message=f"Potential null/undefined risk: {risk.description}",
                line_number=risk.line_number,
                suggestion=f"Consider using optional chaining or null checks"
            ) for risk in nullability_analysis.risks
        ])

    # Promise/asyncä½¿ç”¨ã®é©åˆ‡æ€§
    async_analysis = analyze_async_usage(diff_data.added_lines)
    if async_analysis.has_issues:
        findings.extend([
            ReviewFinding(
                type='ASYNC_HANDLING',
                severity='MEDIUM',
                message=f"Async handling issue: {issue.description}",
                line_number=issue.line_number,
                suggestion=issue.recommended_pattern
            ) for issue in async_analysis.issues
        ])

    return TypeScriptReviewResult(findings=findings)

def perform_security_vulnerability_scan(file_path, diff_data):
    """ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³"""
    findings = []

    # SQL ã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³ ãƒªã‚¹ã‚¯
    sql_injection_risks = scan_sql_injection_risks(diff_data.added_lines)
    findings.extend([
        ReviewFinding(
            type='SECURITY_SQL_INJECTION',
            severity='CRITICAL',
            message=f"Potential SQL injection vulnerability: {risk.pattern}",
            line_number=risk.line_number,
            suggestion="Use parameterized queries or prepared statements"
        ) for risk in sql_injection_risks
    ])

    # èªè¨¼ãƒ»èªå¯ã®ä¸é©åˆ‡ãªå®Ÿè£…
    auth_risks = scan_authentication_issues(diff_data.added_lines)
    findings.extend([
        ReviewFinding(
            type='SECURITY_AUTHENTICATION',
            severity='HIGH',
            message=f"Authentication/Authorization issue: {risk.description}",
            line_number=risk.line_number,
            suggestion=risk.security_best_practice
        ) for risk in auth_risks
    ])

    # æ©Ÿå¯†æƒ…å ±ã®ä¸é©åˆ‡ãªéœ²å‡º
    sensitive_data_risks = scan_sensitive_data_exposure(diff_data.added_lines)
    findings.extend([
        ReviewFinding(
            type='SECURITY_DATA_EXPOSURE',
            severity='HIGH',
            message=f"Potential sensitive data exposure: {risk.data_type}",
            line_number=risk.line_number,
            suggestion="Use environment variables or secure configuration management"
        ) for risk in sensitive_data_risks
    ])

    return SecurityReviewResult(findings=findings)

def analyze_performance_impact(file_path, diff_data):
    """ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹å½±éŸ¿åˆ†æ"""
    findings = []

    # N+1ã‚¯ã‚¨ãƒªå•é¡Œ
    n_plus_one_risks = detect_n_plus_one_patterns(diff_data.added_lines)
    findings.extend([
        ReviewFinding(
            type='PERFORMANCE_N_PLUS_ONE',
            severity='HIGH',
            message=f"Potential N+1 query problem: {risk.query_pattern}",
            line_number=risk.line_number,
            suggestion="Consider using batch loading or joins"
        ) for risk in n_plus_one_risks
    ])

    # éåŠ¹ç‡ãªãƒ«ãƒ¼ãƒ—å‡¦ç†
    loop_inefficiency = detect_inefficient_loops(diff_data.added_lines)
    findings.extend([
        ReviewFinding(
            type='PERFORMANCE_LOOP_INEFFICIENCY',
            severity='MEDIUM',
            message=f"Inefficient loop detected: {issue.pattern}",
            line_number=issue.line_number,
            suggestion=issue.optimization_suggestion
        ) for issue in loop_inefficiency
    ])

    # ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ ãƒªã‚¹ã‚¯
    memory_leak_risks = detect_memory_leak_patterns(diff_data.added_lines)
    findings.extend([
        ReviewFinding(
            type='PERFORMANCE_MEMORY_LEAK',
            severity='HIGH',
            message=f"Potential memory leak: {risk.pattern}",
            line_number=risk.line_number,
            suggestion="Ensure proper cleanup of resources and event listeners"
        ) for risk in memory_leak_risks
    ])

    return PerformanceReviewResult(findings=findings)
```

### **Phase 3: å¤‰æ›´å½±éŸ¿ç¯„å›²åˆ†æ**
```python
def perform_change_impact_analysis(commit_files):
    """å¤‰æ›´å½±éŸ¿ç¯„å›²ã®åŒ…æ‹¬åˆ†æ"""
    impact_analysis = ChangeImpactAnalysis()

    for file_path in commit_files:
        # 1. ç›´æ¥çš„ãªä¾å­˜é–¢ä¿‚åˆ†æ
        direct_dependencies = analyze_direct_dependencies(file_path)
        impact_analysis.add_direct_impacts(file_path, direct_dependencies)

        # 2. é–“æ¥çš„ãªå½±éŸ¿ç¯„å›²åˆ†æ
        indirect_impacts = analyze_indirect_impacts(file_path, direct_dependencies)
        impact_analysis.add_indirect_impacts(file_path, indirect_impacts)

        # 3. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å½±éŸ¿åˆ†æ
        db_impacts = analyze_database_impact(file_path)
        impact_analysis.add_database_impacts(file_path, db_impacts)

        # 4. APIå¥‘ç´„ã¸ã®å½±éŸ¿
        api_impacts = analyze_api_contract_impact(file_path)
        impact_analysis.add_api_impacts(file_path, api_impacts)

        # 5. ãƒ†ã‚¹ãƒˆå½±éŸ¿åˆ†æ
        test_impacts = analyze_test_impact(file_path)
        impact_analysis.add_test_impacts(file_path, test_impacts)

    # ç·åˆçš„ãªå½±éŸ¿è©•ä¾¡
    overall_impact = impact_analysis.calculate_overall_impact()

    return ChangeImpactResult(
        file_impacts=impact_analysis.get_all_impacts(),
        overall_risk_level=overall_impact.risk_level,
        affected_systems=overall_impact.affected_systems,
        required_testing_areas=overall_impact.testing_requirements,
        deployment_considerations=overall_impact.deployment_risks
    )

def analyze_indirect_impacts(file_path, direct_dependencies):
    """é–“æ¥çš„å½±éŸ¿ã®åˆ†æ"""
    indirect_impacts = []

    # ä¾å­˜é–¢ä¿‚ã‚°ãƒ©ãƒ•ã®æ§‹ç¯‰
    dependency_graph = build_dependency_graph(file_path)

    # å½±éŸ¿ã®æ³¢åŠåˆ†æ
    for dependency in direct_dependencies:
        # 2æ®µéšå…ˆã¾ã§å½±éŸ¿ã‚’åˆ†æ
        second_level_deps = get_dependencies_of_file(dependency.file_path)
        for second_dep in second_level_deps:
            impact_severity = calculate_impact_severity(file_path, dependency, second_dep)
            indirect_impacts.append(IndirectImpact(
                source_file=file_path,
                intermediate_file=dependency.file_path,
                affected_file=second_dep.file_path,
                impact_type=second_dep.relationship_type,
                severity=impact_severity
            ))

    return indirect_impacts

def generate_diff_review_report(pre_commit_analysis, code_review_results, impact_analysis):
    """Diffãƒ¬ãƒ“ãƒ¥ãƒ¼ç·åˆãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
    report = {
        'analysis_summary': {
            'total_files_analyzed': len(pre_commit_analysis.file_analyses),
            'overall_risk_level': pre_commit_analysis.overall_risk_level,
            'human_review_required': pre_commit_analysis.human_review_required,
            'blocking_issues_count': len(pre_commit_analysis.blocking_issues)
        },
        'security_findings': {
            'critical_issues': extract_security_critical_issues(code_review_results),
            'high_priority_issues': extract_security_high_issues(code_review_results),
            'recommendations': generate_security_recommendations(code_review_results)
        },
        'performance_findings': {
            'performance_risks': extract_performance_risks(code_review_results),
            'optimization_opportunities': extract_optimization_suggestions(code_review_results)
        },
        'impact_analysis': {
            'affected_systems': impact_analysis.affected_systems,
            'testing_requirements': impact_analysis.required_testing_areas,
            'deployment_risks': impact_analysis.deployment_considerations
        },
        'approval_recommendation': {
            'can_auto_approve': determine_auto_approval_eligibility(
                pre_commit_analysis, code_review_results, impact_analysis
            ),
            'required_approvals': determine_required_approvals(
                pre_commit_analysis.overall_risk_level, impact_analysis.overall_risk_level
            ),
            'next_actions': generate_next_action_recommendations(
                pre_commit_analysis, code_review_results, impact_analysis
            )
        }
    }

    return DiffReviewReport(report)
```

## ğŸ“Š **æœŸå¾…ã•ã‚Œã‚‹æ”¹å–„åŠ¹æœ**

### **å“è³ªå‘ä¸ŠåŠ¹æœ**
```yaml
Quality_Improvement_Benefits:
  code_quality_issues_detection:
    before: "åŸºæœ¬çš„ãªæ§‹æ–‡ã‚¨ãƒ©ãƒ¼ã®ã¿æ¤œçŸ¥"
    after: "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒ»ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒ»è¦ç´„é•åã‚’åŒ…æ‹¬æ¤œçŸ¥"
    improvement: "ã‚³ãƒ¼ãƒ‰å“è³ªå•é¡Œã®æ¤œçŸ¥ç‡90%å‘ä¸Š"

  security_vulnerability_prevention:
    before: "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®è¦‹è½ã¨ã—"
    after: "è‡ªå‹•ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³ãƒ»æ—©æœŸç™ºè¦‹"
    improvement: "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆãƒªã‚¹ã‚¯80%å‰Šæ¸›"

  change_impact_understanding:
    before: "å¤‰æ›´å½±éŸ¿ã®äºˆæ¸¬å›°é›£"
    after: "åŒ…æ‹¬çš„å½±éŸ¿ç¯„å›²åˆ†æãƒ»ãƒªã‚¹ã‚¯äºˆæ¸¬"
    improvement: "äºˆæœŸã—ãªã„ä¸å…·åˆ90%å‰Šæ¸›"
```

### **é–‹ç™ºåŠ¹ç‡å‘ä¸Š**
```yaml
Development_Efficiency_Gains:
  review_time_reduction:
    before: "äººé–“ã«ã‚ˆã‚‹å…¨é¢çš„ãƒ¬ãƒ“ãƒ¥ãƒ¼å¿…è¦"
    after: "è‡ªå‹•ãƒ¬ãƒ“ãƒ¥ãƒ¼ã«ã‚ˆã‚‹äº‹å‰ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°"
    improvement: "ãƒ¬ãƒ“ãƒ¥ãƒ¼æ™‚é–“70%çŸ­ç¸®"

  issue_early_detection:
    before: "æœ¬ç•ªãƒ‡ãƒ—ãƒ­ã‚¤å¾Œã®å•é¡Œç™ºè¦‹"
    after: "ã‚³ãƒŸãƒƒãƒˆå‰ã®å•é¡Œæ—©æœŸç™ºè¦‹ãƒ»ä¿®æ­£"
    improvement: "ãƒã‚°ä¿®æ­£ã‚³ã‚¹ãƒˆ85%å‰Šæ¸›"

  development_confidence:
    before: "å¤‰æ›´ã¸ã®ä¸å®‰ãƒ»æ…é‡ãªãƒ‡ãƒ—ãƒ­ã‚¤"
    after: "åŒ…æ‹¬åˆ†æã«ã‚ˆã‚‹ç¢ºä¿¡ã‚’æŒã£ãŸé–‹ç™º"
    improvement: "é–‹ç™ºé€Ÿåº¦30%å‘ä¸Š"
```

## ğŸš¨ **å®Ÿè£…å„ªå…ˆåº¦**

### **ç·Šæ€¥å®Ÿè£…é …ç›®ï¼ˆä»Šé€±ä¸­ï¼‰**
```yaml
Immediate_Implementation:
  pre_commit_diff_analysis:
    priority: "HIGH"
    function: "perform_pre_commit_diff_analysis()"
    benefit: "å±é™ºãªå¤‰æ›´ã®äº‹å‰æ¤œçŸ¥ãƒ»å“è³ªå‘ä¸Š"

  basic_security_scan:
    priority: "HIGH"
    function: "perform_security_vulnerability_scan()"
    benefit: "ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯æ—©æœŸç™ºè¦‹"
```

### **ä¸­æœŸå®Ÿè£…é …ç›®ï¼ˆ2é€±é–“ä»¥å†…ï¼‰**
```yaml
Medium_Term_Implementation:
  automated_code_review:
    priority: "MEDIUM"
    functions: ["perform_automated_code_review()", "perform_typescript_review()"]
    benefit: "åŒ…æ‹¬çš„ã‚³ãƒ¼ãƒ‰å“è³ªå‘ä¸Š"

  change_impact_analysis:
    priority: "MEDIUM"
    functions: ["perform_change_impact_analysis()", "analyze_indirect_impacts()"]
    benefit: "å¤‰æ›´ãƒªã‚¹ã‚¯ã®äº‹å‰è©•ä¾¡"
```

## ğŸ¯ **çµè«–**

**agent-orchestratorã«ã¯ã€GitHubã®æ¨™æº–çš„ãªç®¡ç†ãƒ•ãƒ­ãƒ¼ã«å¿…è¦ãªdiffãƒã‚§ãƒƒã‚¯ãƒ»ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½ãŒå®Œå…¨ã«æ¬ å¦‚ã—ã¦ãŠã‚Šã€ç·Šæ€¥ã®æ©Ÿèƒ½è¿½åŠ ãŒå¿…è¦ã§ã™ã€‚**

ç‰¹ã«ä»¥ä¸‹ã®æ©Ÿèƒ½ãŒæœ€å„ªå…ˆã§å®Ÿè£…ã•ã‚Œã‚‹ã¹ãã§ã™ï¼š

1. **Pre-Commitãƒ‡ã‚£ãƒ•åˆ†ææ©Ÿèƒ½**
2. **è‡ªå‹•ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£è„†å¼±æ€§ã‚¹ã‚­ãƒ£ãƒ³**
3. **å¤‰æ›´å½±éŸ¿ç¯„å›²åˆ†æ**
4. **è‡ªå‹•ã‚³ãƒ¼ãƒ‰ãƒ¬ãƒ“ãƒ¥ãƒ¼æ©Ÿèƒ½**

ã“ã‚Œã‚‰ã®æ©Ÿèƒ½ã«ã‚ˆã‚Šã€ã‚³ãƒ¼ãƒ‰å“è³ªã®å¤§å¹…å‘ä¸Šã¨ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒªã‚¹ã‚¯ã®æ—©æœŸç™ºè¦‹ãŒå®Ÿç¾ã•ã‚Œã€GitHubç®¡ç†ãƒ•ãƒ­ãƒ¼ã¨ã®é©åˆæ€§ãŒå¤§å¹…ã«æ”¹å–„ã•ã‚Œã¾ã™ã€‚
