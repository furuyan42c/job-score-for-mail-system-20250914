# ğŸš€ ãƒã‚¤ãƒˆæ±‚äººãƒãƒƒãƒãƒ³ã‚°ã‚·ã‚¹ãƒ†ãƒ  é‹ç”¨ãƒãƒ‹ãƒ¥ã‚¢ãƒ«

## ç›®æ¬¡
1. [ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦](#ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦)
2. [ç’°å¢ƒæ§‹æˆ](#ç’°å¢ƒæ§‹æˆ)
3. [ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †](#ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †)
4. [é‹ç”¨æ‰‹é †](#é‹ç”¨æ‰‹é †)
5. [ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ](#ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ)
6. [ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°](#ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°)
7. [ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°](#ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°)
8. [ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚«ãƒãƒª](#ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚«ãƒãƒª)
9. [ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£](#ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£)
10. [ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹](#ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹)

---

## ã‚·ã‚¹ãƒ†ãƒ æ¦‚è¦

### ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Frontend  â”‚â”€â”€â”€â”€â–¶â”‚   Backend   â”‚â”€â”€â”€â”€â–¶â”‚  PostgreSQL â”‚
â”‚   (Next.js) â”‚     â”‚  (FastAPI)  â”‚     â”‚  (Supabase) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚                     â”‚
                           â–¼                     â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚    Redis    â”‚     â”‚   S3/CDN    â”‚
                    â”‚   (Cache)   â”‚     â”‚  (Storage)  â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
- **Frontend**: Next.js 14 (App Router)
- **Backend**: FastAPI + SQLAlchemy
- **Database**: PostgreSQL 15 / Supabase
- **Cache**: Redis 7
- **Queue**: Celery + Redis
- **Monitoring**: Prometheus + Grafana
- **Logging**: ELK Stack
- **Error Tracking**: Sentry

---

## ç’°å¢ƒæ§‹æˆ

### ç’°å¢ƒå¤‰æ•°è¨­å®š

#### å¿…é ˆç’°å¢ƒå¤‰æ•°
```bash
# Database
DATABASE_URL=postgresql://user:pass@host:5432/dbname
SUPABASE_URL=https://xxx.supabase.co
SUPABASE_ANON_KEY=xxx
SUPABASE_SERVICE_ROLE_KEY=xxx

# Security
SECRET_KEY=your-secret-key-minimum-32-chars
JWT_SECRET_KEY=your-jwt-secret

# Redis
REDIS_URL=redis://localhost:6379/0

# Email
SMTP_HOST=smtp.gmail.com
SMTP_PORT=587
SMTP_USER=your-email@gmail.com
SMTP_PASSWORD=your-app-password
FROM_EMAIL=noreply@example.com

# Monitoring
SENTRY_DSN=https://xxx@sentry.io/xxx
```

### ç’°å¢ƒåˆ¥è¨­å®š

#### Development
```bash
cp .env.example .env
# Edit .env with development values
docker-compose up -d
```

#### Staging
```bash
cp .env.staging.example .env
# Edit .env with staging values
docker-compose -f docker-compose.yml -f docker-compose.staging.yml up -d
```

#### Production
```bash
cp .env.production.example .env
# Edit .env with production values
docker-compose -f docker-compose.yml -f docker-compose.prod.yml up -d
```

---

## ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆæ‰‹é †

### åˆå›ãƒ‡ãƒ—ãƒ­ã‚¤

#### 1. ã‚¤ãƒ³ãƒ•ãƒ©æº–å‚™
```bash
# AWS ãƒªã‚½ãƒ¼ã‚¹ã®ä½œæˆ
terraform init
terraform plan -out=tfplan
terraform apply tfplan

# Supabase ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ä½œæˆ
supabase init
supabase start
```

#### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹åˆæœŸåŒ–
```bash
# ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³å®Ÿè¡Œ
cd backend
alembic upgrade head

# åˆæœŸãƒ‡ãƒ¼ã‚¿æŠ•å…¥
python scripts/seed_master_data.py
python scripts/generate_sample_data.py
```

#### 3. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
```bash
# Docker ã‚¤ãƒ¡ãƒ¼ã‚¸ãƒ“ãƒ«ãƒ‰
docker build -t job-matching-backend:latest ./backend
docker build -t job-matching-frontend:latest ./frontend

# ã‚³ãƒ³ãƒ†ãƒŠèµ·å‹•
docker-compose up -d

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/health
```

### æ›´æ–°ãƒ‡ãƒ—ãƒ­ã‚¤

#### Blue-Green ãƒ‡ãƒ—ãƒ­ã‚¤ãƒ¡ãƒ³ãƒˆ
```bash
# æ–°ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã®ãƒ“ãƒ«ãƒ‰
docker build -t job-matching-backend:v2.0.0 ./backend
docker build -t job-matching-frontend:v2.0.0 ./frontend

# æ–°ç’°å¢ƒèµ·å‹•ï¼ˆGreenï¼‰
docker-compose -p green up -d

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
./scripts/health_check.sh green

# ãƒˆãƒ©ãƒ•ã‚£ãƒƒã‚¯åˆ‡ã‚Šæ›¿ãˆ
./scripts/switch_traffic.sh green

# æ—§ç’°å¢ƒåœæ­¢ï¼ˆBlueï¼‰
docker-compose -p blue down
```

#### ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
```bash
# Kubernetes ã§ã®ãƒ­ãƒ¼ãƒªãƒ³ã‚°ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
kubectl set image deployment/backend backend=job-matching-backend:v2.0.0
kubectl rollout status deployment/backend

kubectl set image deployment/frontend frontend=job-matching-frontend:v2.0.0
kubectl rollout status deployment/frontend
```

---

## é‹ç”¨æ‰‹é †

### æ—¥æ¬¡é‹ç”¨

#### 1. ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
```bash
# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯
curl http://localhost:8000/health

# ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç¢ºèª
curl http://localhost:8000/metrics

# ãƒ­ã‚°ç¢ºèª
docker-compose logs --tail=100 -f backend
```

#### 2. ãƒãƒƒãƒå‡¦ç†å®Ÿè¡Œ
```bash
# æ—¥æ¬¡ãƒãƒƒãƒãƒ³ã‚°å‡¦ç†
curl -X POST http://localhost:8000/api/v1/batch/trigger \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"batch_type": "daily_matching"}'

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
curl http://localhost:8000/api/v1/batch/status/batch-id
```

#### 3. ãƒ‡ãƒ¼ã‚¿ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```bash
# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
pg_dump $DATABASE_URL > backup_$(date +%Y%m%d).sql

# S3ã¸ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
aws s3 cp backup_$(date +%Y%m%d).sql s3://backup-bucket/
```

### é€±æ¬¡é‹ç”¨

#### 1. ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹åˆ†æ
```sql
-- ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªç¢ºèª
SELECT query, calls, mean_exec_time
FROM pg_stat_statements
WHERE mean_exec_time > 1000
ORDER BY mean_exec_time DESC;

-- ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½¿ç”¨çŠ¶æ³
SELECT schemaname, tablename, indexname, idx_scan
FROM pg_stat_user_indexes
ORDER BY idx_scan;
```

#### 2. ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»
```bash
# ä¾å­˜é–¢ä¿‚ã®è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
cd backend && safety check
cd frontend && npm audit

# ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°åˆ†æ
./scripts/analyze_access_logs.sh
```

### æœˆæ¬¡é‹ç”¨

#### 1. ã‚­ãƒ£ãƒ‘ã‚·ãƒ†ã‚£ãƒ—ãƒ©ãƒ³ãƒ‹ãƒ³ã‚°
```bash
# ãƒªã‚½ãƒ¼ã‚¹ä½¿ç”¨çŠ¶æ³ãƒ¬ãƒãƒ¼ãƒˆ
./scripts/generate_capacity_report.sh

# æˆé•·äºˆæ¸¬
python scripts/predict_growth.py
```

#### 2. ãƒ‡ã‚£ã‚¶ã‚¹ã‚¿ãƒªã‚«ãƒãƒªãƒ†ã‚¹ãƒˆ
```bash
# ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰ã®å¾©å…ƒãƒ†ã‚¹ãƒˆ
./scripts/disaster_recovery_test.sh
```

---

## ç›£è¦–ã¨ã‚¢ãƒ©ãƒ¼ãƒˆ

### ãƒ¡ãƒˆãƒªã‚¯ã‚¹ç›£è¦–

#### Prometheusè¨­å®š
```yaml
# prometheus.yml
global:
  scrape_interval: 15s
  evaluation_interval: 15s

scrape_configs:
  - job_name: 'backend'
    static_configs:
      - targets: ['backend:8000']
    metrics_path: /metrics

  - job_name: 'batch-processor'
    static_configs:
      - targets: ['batch-processor:8001']
```

#### ä¸»è¦ãƒ¡ãƒˆãƒªã‚¯ã‚¹
- **API Response Time**: < 200ms (p95)
- **Database Query Time**: < 100ms (p95)
- **Error Rate**: < 0.1%
- **CPU Usage**: < 70%
- **Memory Usage**: < 80%
- **Disk Usage**: < 85%

### ã‚¢ãƒ©ãƒ¼ãƒˆè¨­å®š

#### Critical ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆå³æ™‚å¯¾å¿œï¼‰
```yaml
- alert: HighErrorRate
  expr: rate(http_requests_total{status=~"5.."}[5m]) > 0.01
  annotations:
    summary: "High error rate detected"
    description: "Error rate is {{ $value }}%"

- alert: DatabaseDown
  expr: up{job="postgres"} == 0
  annotations:
    summary: "Database is down"
```

#### Warning ã‚¢ãƒ©ãƒ¼ãƒˆï¼ˆå–¶æ¥­æ™‚é–“å†…å¯¾å¿œï¼‰
```yaml
- alert: HighMemoryUsage
  expr: memory_usage_percent > 80
  for: 10m
  annotations:
    summary: "Memory usage is high"

- alert: SlowQueries
  expr: database_query_duration_seconds > 1
  for: 5m
```

### ãƒ­ã‚°ç®¡ç†

#### ãƒ­ã‚°ãƒ¬ãƒ™ãƒ«
- **ERROR**: ã‚¨ãƒ©ãƒ¼ç™ºç”Ÿï¼ˆè¦èª¿æŸ»ï¼‰
- **WARNING**: è­¦å‘Šï¼ˆç›£è¦–ç¶™ç¶šï¼‰
- **INFO**: é€šå¸¸å‹•ä½œ
- **DEBUG**: ãƒ‡ãƒãƒƒã‚°æƒ…å ±ï¼ˆé–‹ç™ºç’°å¢ƒã®ã¿ï¼‰

#### ãƒ­ã‚°åˆ†æã‚¯ã‚¨ãƒª
```json
// Kibana ã§ã®ã‚¨ãƒ©ãƒ¼æ¤œç´¢
{
  "query": {
    "bool": {
      "must": [
        {"match": {"level": "ERROR"}},
        {"range": {"@timestamp": {"gte": "now-1h"}}}
      ]
    }
  }
}
```

---

## ãƒˆãƒ©ãƒ–ãƒ«ã‚·ãƒ¥ãƒ¼ãƒ†ã‚£ãƒ³ã‚°

### ã‚ˆãã‚ã‚‹å•é¡Œã¨å¯¾å‡¦æ³•

#### 1. API ãƒ¬ã‚¹ãƒãƒ³ã‚¹ãŒé…ã„
```bash
# åŸå› èª¿æŸ»
# 1. ã‚¹ãƒ­ãƒ¼ã‚¯ã‚¨ãƒªã®ç¢ºèª
docker exec -it postgres psql -U postgres -c "SELECT * FROM pg_stat_statements ORDER BY mean_exec_time DESC LIMIT 10;"

# 2. Redisæ¥ç¶šç¢ºèª
redis-cli ping

# 3. CPU/ãƒ¡ãƒ¢ãƒªç¢ºèª
docker stats

# å¯¾å‡¦æ³•
# - ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹è¿½åŠ 
# - ã‚¯ã‚¨ãƒªæœ€é©åŒ–
# - ã‚­ãƒ£ãƒƒã‚·ãƒ¥æˆ¦ç•¥è¦‹ç›´ã—
# - ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
```

#### 2. ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶šã‚¨ãƒ©ãƒ¼
```bash
# æ¥ç¶šãƒ—ãƒ¼ãƒ«çŠ¶æ…‹ç¢ºèª
curl http://localhost:8000/system-info | jq .database.pool_stats

# å¯¾å‡¦æ³•
# - æ¥ç¶šãƒ—ãƒ¼ãƒ«ã‚µã‚¤ã‚ºèª¿æ•´
export DB_POOL_SIZE=30
export DB_MAX_OVERFLOW=50

# - ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†èµ·å‹•
docker-compose restart postgres
```

#### 3. ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯
```bash
# ãƒ¡ãƒ¢ãƒªä½¿ç”¨çŠ¶æ³ç¢ºèª
docker exec backend ps aux --sort=-rss | head

# Python ãƒ¡ãƒ¢ãƒªãƒ—ãƒ­ãƒ•ã‚¡ã‚¤ãƒªãƒ³ã‚°
python -m memory_profiler app/main.py

# å¯¾å‡¦æ³•
# - ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å†èµ·å‹•
docker-compose restart backend

# - ãƒ¡ãƒ¢ãƒªãƒªãƒ¼ã‚¯ç®‡æ‰€ã®ç‰¹å®šã¨ä¿®æ­£
```

#### 4. ãƒãƒƒãƒå‡¦ç†å¤±æ•—
```bash
# ãƒ­ã‚°ç¢ºèª
docker logs batch-processor --tail=1000 | grep ERROR

# æ‰‹å‹•ãƒªãƒˆãƒ©ã‚¤
curl -X POST http://localhost:8000/api/v1/batch/retry/batch-id

# ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ãƒã‚§ãƒƒã‚¯
python scripts/check_data_integrity.py
```

### ç·Šæ€¥å¯¾å¿œæ‰‹é †

#### ã‚·ã‚¹ãƒ†ãƒ å®Œå…¨åœæ­¢æ™‚
```bash
# 1. ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
docker-compose ps
systemctl status nginx

# 2. ã‚µãƒ¼ãƒ“ã‚¹å†èµ·å‹•
docker-compose down
docker-compose up -d

# 3. ãƒ­ã‚°åé›†
./scripts/collect_emergency_logs.sh

# 4. ã‚¤ãƒ³ã‚·ãƒ‡ãƒ³ãƒˆå ±å‘Š
./scripts/create_incident_report.sh
```

#### ãƒ‡ãƒ¼ã‚¿ç ´ææ™‚
```bash
# 1. å½±éŸ¿ç¯„å›²ç¢ºèª
psql $DATABASE_URL -c "SELECT COUNT(*) FROM corrupted_table;"

# 2. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‹ã‚‰å¾©å…ƒ
pg_restore -d $DATABASE_URL backup_latest.sql

# 3. å·®åˆ†ãƒ‡ãƒ¼ã‚¿é©ç”¨
python scripts/apply_delta_data.py
```

---

## ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

### å‚ç›´ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### ãƒªã‚½ãƒ¼ã‚¹å¢—å¼·
```yaml
# docker-compose.yml
services:
  backend:
    deploy:
      resources:
        limits:
          cpus: '4.0'  # 2.0 â†’ 4.0
          memory: 4GB   # 2GB â†’ 4GB
```

### æ°´å¹³ã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### Backend ã‚¹ã‚±ãƒ¼ãƒ«ã‚¢ã‚¦ãƒˆ
```bash
# Docker Swarm
docker service scale backend=5

# Kubernetes
kubectl scale deployment backend --replicas=5

# è² è·åˆ†æ•£è¨­å®š
upstream backend_servers {
    least_conn;
    server backend1:8000;
    server backend2:8000;
    server backend3:8000;
    server backend4:8000;
    server backend5:8000;
}
```

#### Database ãƒ¬ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³
```sql
-- ãƒ—ãƒ©ã‚¤ãƒãƒªè¨­å®š
ALTER SYSTEM SET wal_level = replica;
ALTER SYSTEM SET max_wal_senders = 10;
ALTER SYSTEM SET wal_keep_segments = 64;

-- ãƒ¬ãƒ—ãƒªã‚«è¿½åŠ 
pg_basebackup -h primary -D /var/lib/postgresql/data -P -U replicator
```

### ã‚ªãƒ¼ãƒˆã‚¹ã‚±ãƒ¼ãƒªãƒ³ã‚°

#### AWS Auto Scaling
```yaml
# terraform/autoscaling.tf
resource "aws_autoscaling_group" "backend" {
  min_size             = 2
  max_size             = 10
  desired_capacity     = 3

  target_group_arns    = [aws_lb_target_group.backend.arn]
  health_check_type    = "ELB"

  tag {
    key                 = "Name"
    value               = "backend-asg"
    propagate_at_launch = true
  }
}

resource "aws_autoscaling_policy" "backend_cpu" {
  name                   = "backend-cpu-policy"
  autoscaling_group_name = aws_autoscaling_group.backend.name
  policy_type            = "TargetTrackingScaling"

  target_tracking_configuration {
    predefined_metric_specification {
      predefined_metric_type = "ASGAverageCPUUtilization"
    }
    target_value = 70.0
  }
}
```

---

## ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã¨ãƒªã‚«ãƒãƒª

### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—æˆ¦ç•¥

#### è‡ªå‹•ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
```bash
# crontab -e
# æ—¥æ¬¡ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ·±å¤œ2æ™‚ï¼‰
0 2 * * * /scripts/daily_backup.sh

# é€±æ¬¡ãƒ•ãƒ«ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ï¼ˆæ—¥æ›œæ·±å¤œï¼‰
0 3 * * 0 /scripts/weekly_full_backup.sh

# æœˆæ¬¡ã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ï¼ˆæœˆåˆï¼‰
0 4 1 * * /scripts/monthly_archive.sh
```

#### ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# daily_backup.sh

DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_DIR="/backups"
S3_BUCKET="s3://backup-bucket"

# Database backup
pg_dump $DATABASE_URL | gzip > $BACKUP_DIR/db_$DATE.sql.gz

# Redis backup
redis-cli --rdb $BACKUP_DIR/redis_$DATE.rdb

# Upload to S3
aws s3 sync $BACKUP_DIR $S3_BUCKET/daily/

# Cleanup old backups (keep 30 days)
find $BACKUP_DIR -name "*.gz" -mtime +30 -delete
```

### ãƒªã‚«ãƒãƒªæ‰‹é †

#### Point-in-Time Recovery
```bash
# 1. WALã‚¢ãƒ¼ã‚«ã‚¤ãƒ–ã‹ã‚‰ç‰¹å®šæ™‚ç‚¹ã¾ã§å¾©å…ƒ
pg_basebackup -D /var/lib/postgresql/recovery -R

# 2. recovery.conf è¨­å®š
cat > /var/lib/postgresql/recovery/recovery.conf <<EOF
restore_command = 'cp /archive/%f %p'
recovery_target_time = '2024-01-15 14:30:00'
recovery_target_action = 'promote'
EOF

# 3. PostgreSQL èµ·å‹•
pg_ctl start -D /var/lib/postgresql/recovery
```

#### ç½å®³å¾©æ—§
```bash
# 1. æ–°ç’°å¢ƒæ§‹ç¯‰
terraform apply -auto-approve

# 2. æœ€æ–°ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—å–å¾—
aws s3 cp s3://backup-bucket/latest/db_backup.sql.gz .

# 3. ãƒ‡ãƒ¼ã‚¿å¾©å…ƒ
gunzip -c db_backup.sql.gz | psql $NEW_DATABASE_URL

# 4. ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ‡ãƒ—ãƒ­ã‚¤
kubectl apply -f k8s/

# 5. DNSåˆ‡ã‚Šæ›¿ãˆ
aws route53 change-resource-record-sets --hosted-zone-id Z123 --change-batch file://dns-failover.json
```

---

## ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ãƒã‚§ãƒƒã‚¯ãƒªã‚¹ãƒˆ

#### ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- [ ] HTTPSé€šä¿¡ã®å¼·åˆ¶
- [ ] SQLã‚¤ãƒ³ã‚¸ã‚§ã‚¯ã‚·ãƒ§ãƒ³å¯¾ç­–
- [ ] XSSå¯¾ç­–
- [ ] CSRFå¯¾ç­–
- [ ] èªè¨¼ãƒ»èªå¯ã®å®Ÿè£…
- [ ] ãƒ¬ãƒ¼ãƒˆåˆ¶é™
- [ ] å…¥åŠ›æ¤œè¨¼
- [ ] ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã®é©åˆ‡ãªå‡¦ç†

#### ã‚¤ãƒ³ãƒ•ãƒ©ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£
- [ ] ãƒ•ã‚¡ã‚¤ã‚¢ã‚¦ã‚©ãƒ¼ãƒ«è¨­å®š
- [ ] ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯ã‚»ã‚°ãƒ¡ãƒ³ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
- [ ] æœ€å°æ¨©é™ã®åŸå‰‡
- [ ] å®šæœŸçš„ãªãƒ‘ãƒƒãƒé©ç”¨
- [ ] ãƒ­ã‚°ç›£è¦–
- [ ] ä¾µå…¥æ¤œçŸ¥ã‚·ã‚¹ãƒ†ãƒ 

### ã‚»ã‚­ãƒ¥ãƒªãƒ†ã‚£ç›£æŸ»

#### å®šæœŸç›£æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
```bash
#!/bin/bash
# security_audit.sh

echo "=== Security Audit Report ===="
date

# 1. ä¾å­˜é–¢ä¿‚ã®è„†å¼±æ€§ãƒã‚§ãƒƒã‚¯
echo "## Python Dependencies"
cd backend && safety check

echo "## Node Dependencies"
cd ../frontend && npm audit

# 2. ã‚ªãƒ¼ãƒ—ãƒ³ãƒãƒ¼ãƒˆãƒã‚§ãƒƒã‚¯
echo "## Open Ports"
nmap -p- localhost

# 3. SSLè¨¼æ˜æ›¸ãƒã‚§ãƒƒã‚¯
echo "## SSL Certificate"
openssl s_client -connect example.com:443 -servername example.com < /dev/null

# 4. ã‚¢ã‚¯ã‚»ã‚¹ãƒ­ã‚°åˆ†æ
echo "## Suspicious Access"
grep -E "(\.\./|SELECT|UNION|DROP)" /var/log/nginx/access.log | tail -20

# 5. æ¨©é™ãƒã‚§ãƒƒã‚¯
echo "## File Permissions"
find /app -type f -perm /o+w -ls
```

---

## ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

### å®šæœŸãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹

#### æœˆæ¬¡ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹
```bash
# 1. ã‚·ã‚¹ãƒ†ãƒ ã‚¢ãƒƒãƒ—ãƒ‡ãƒ¼ãƒˆ
apt-get update && apt-get upgrade -y

# 2. Docker ã‚¤ãƒ¡ãƒ¼ã‚¸æ›´æ–°
docker-compose pull
docker-compose up -d

# 3. ãƒ­ã‚°ãƒ­ãƒ¼ãƒ†ãƒ¼ã‚·ãƒ§ãƒ³
logrotate -f /etc/logrotate.conf

# 4. ä¸è¦ãƒ‡ãƒ¼ã‚¿ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
python scripts/cleanup_old_data.py

# 5. ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹å†æ§‹ç¯‰
psql $DATABASE_URL -c "REINDEX DATABASE job_matching;"
```

### ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰

#### ãƒã‚¤ãƒŠãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—
```bash
# 1. å¤‰æ›´å†…å®¹ç¢ºèª
git diff v1.2.0..v1.3.0

# 2. ãƒ†ã‚¹ãƒˆç’°å¢ƒã§æ¤œè¨¼
docker-compose -f docker-compose.test.yml up
pytest tests/

# 3. æœ¬ç•ªé©ç”¨
./scripts/rolling_update.sh v1.3.0
```

#### ãƒ¡ã‚¸ãƒ£ãƒ¼ãƒãƒ¼ã‚¸ãƒ§ãƒ³ã‚¢ãƒƒãƒ—
```bash
# 1. äº’æ›æ€§ãƒã‚§ãƒƒã‚¯
python scripts/check_compatibility.py v2.0.0

# 2. ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ã‚°ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³æº–å‚™
alembic revision --autogenerate -m "v2.0.0 migration"

# 3. ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰
./scripts/enable_maintenance_mode.sh

# 4. ãƒãƒƒã‚¯ã‚¢ãƒƒãƒ—
./scripts/full_backup.sh

# 5. ã‚¢ãƒƒãƒ—ã‚°ãƒ¬ãƒ¼ãƒ‰å®Ÿè¡Œ
./scripts/major_upgrade.sh v2.0.0

# 6. å‹•ä½œç¢ºèª
./scripts/smoke_test.sh

# 7. ãƒ¡ãƒ³ãƒ†ãƒŠãƒ³ã‚¹ãƒ¢ãƒ¼ãƒ‰è§£é™¤
./scripts/disable_maintenance_mode.sh
```

---

## ä»˜éŒ²

### ä¾¿åˆ©ãªã‚³ãƒãƒ³ãƒ‰é›†

```bash
# ãƒ­ã‚°æ¤œç´¢
docker-compose logs backend | grep ERROR

# ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ ãƒ¡ãƒˆãƒªã‚¯ã‚¹
watch -n 1 'curl -s localhost:8000/metrics | grep http_requests'

# ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
docker exec -it postgres psql -U postgres -d job_matching

# Redis CLI
docker exec -it redis redis-cli

# ãƒãƒƒãƒå®Ÿè¡ŒçŠ¶æ³
curl localhost:8000/api/v1/batch/status | jq

# ãƒ˜ãƒ«ã‚¹ãƒã‚§ãƒƒã‚¯ãƒ«ãƒ¼ãƒ—
while true; do curl -s localhost:8000/health | jq .status; sleep 5; done
```

### é€£çµ¡å…ˆ

#### ã‚¨ã‚¹ã‚«ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³
1. **L1 ã‚µãƒãƒ¼ãƒˆ**: support@example.com
2. **L2 ã‚¨ãƒ³ã‚¸ãƒ‹ã‚¢**: eng-team@example.com
3. **L3 ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒˆ**: architect@example.com
4. **ç·Šæ€¥é€£çµ¡**: +81-90-XXXX-XXXX

#### å¤–éƒ¨ãƒ™ãƒ³ãƒ€ãƒ¼
- **AWS ã‚µãƒãƒ¼ãƒˆ**: https://console.aws.amazon.com/support
- **Supabase ã‚µãƒãƒ¼ãƒˆ**: support@supabase.com
- **Sentry**: https://sentry.io/support

---

æœ€çµ‚æ›´æ–°: 2025-09-19
ãƒãƒ¼ã‚¸ãƒ§ãƒ³: 1.0.0